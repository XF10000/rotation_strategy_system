"""
æ•°æ®é¢„å¤„ç†å™¨æ¨¡å—
æä¾›æ•°æ®éªŒè¯ã€æ¸…æ´—å’Œæ ¼å¼è½¬æ¢åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import logging
from typing import Tuple, List, Optional

from .exceptions import DataProcessError

logger = logging.getLogger(__name__)

class DataProcessor:
    """æ•°æ®é¢„å¤„ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨"""
        self.required_columns = ['open', 'high', 'low', 'close', 'volume']
        self.dividend_columns = ['dividend_amount', 'allotment_ratio', 'allotment_price', 
                               'bonus_ratio', 'transfer_ratio']
        logger.info("åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨")
    
    def validate_data(self, df: pd.DataFrame) -> Tuple[bool, List[str]]:
        """
        éªŒè¯æ•°æ®å®Œæ•´æ€§
        
        Args:
            df: åŸå§‹æ•°æ®
            
        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦æœ‰æ•ˆ, é—®é¢˜åˆ—è¡¨)
        """
        issues = []
        
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
            if df is None or df.empty:
                issues.append("æ•°æ®ä¸ºç©º")
                return False, issues
            
            # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            missing_columns = [col for col in self.required_columns if col not in df.columns]
            if missing_columns:
                issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            
            # æ£€æŸ¥åˆ†çº¢é…è‚¡åˆ—ï¼ˆå¯é€‰ï¼‰
            dividend_columns_present = [col for col in self.dividend_columns if col in df.columns]
            if dividend_columns_present:
                logger.debug(f"å‘ç°åˆ†çº¢é…è‚¡åˆ—: {dividend_columns_present}")
                # éªŒè¯åˆ†çº¢é…è‚¡æ•°æ®çš„æ•°å€¼ç±»å‹
                for col in dividend_columns_present:
                    if not pd.api.types.is_numeric_dtype(df[col]):
                        issues.append(f"åˆ†çº¢é…è‚¡åˆ— {col} ä¸æ˜¯æ•°å€¼ç±»å‹")
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            for col in ['open', 'high', 'low', 'close']:
                if col in df.columns and not pd.api.types.is_numeric_dtype(df[col]):
                    issues.append(f"åˆ— {col} ä¸æ˜¯æ•°å€¼ç±»å‹")
            
            # æ£€æŸ¥OHLCé€»è¾‘
            if all(col in df.columns for col in ['open', 'high', 'low', 'close']):
                invalid_ohlc = self._check_ohlc_logic(df)
                if invalid_ohlc > 0:
                    issues.append(f"å‘ç° {invalid_ohlc} æ¡OHLCé€»è¾‘é”™è¯¯çš„è®°å½•")
            
            # æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹
            if not df.empty:
                missing_ratio = df.isnull().sum().sum() / (len(df) * len(df.columns))
                if missing_ratio > 0.05:  # è¶…è¿‡5%çš„ç¼ºå¤±å€¼
                    issues.append(f"ç¼ºå¤±å€¼æ¯”ä¾‹è¿‡é«˜: {missing_ratio:.2%}")
            
            # æ£€æŸ¥å¼‚å¸¸å€¼
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if col in df.columns:
                    if (df[col] <= 0).any():
                        issues.append(f"åˆ— {col} å­˜åœ¨éæ­£æ•°å€¼")
                    
                    # æ£€æŸ¥æç«¯å€¼ï¼ˆä»·æ ¼å˜åŒ–è¶…è¿‡50%ï¼‰
                    if len(df) > 1:
                        pct_change = df[col].pct_change().abs()
                        extreme_changes = (pct_change > 0.5).sum()
                        if extreme_changes > 0:
                            issues.append(f"åˆ— {col} å­˜åœ¨ {extreme_changes} ä¸ªæç«¯å˜åŒ–å€¼")
            
            # æ£€æŸ¥æˆäº¤é‡
            if 'volume' in df.columns:
                if (df['volume'] < 0).any():
                    issues.append("æˆäº¤é‡å­˜åœ¨è´Ÿæ•°")
            
            # æ£€æŸ¥æ—¥æœŸç´¢å¼•
            if not isinstance(df.index, pd.DatetimeIndex):
                issues.append("ç´¢å¼•ä¸æ˜¯æ—¥æœŸç±»å‹")
            elif not df.index.is_monotonic_increasing:
                issues.append("æ—¥æœŸç´¢å¼•ä¸æ˜¯é€’å¢é¡ºåº")
            
            is_valid = len(issues) == 0
            return is_valid, issues
            
        except Exception as e:
            issues.append(f"æ•°æ®éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return False, issues
    
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ¸…æ´—æ•°æ®ï¼ˆå¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ç­‰ï¼‰
        
        Args:
            df: åŸå§‹æ•°æ®
            
        Returns:
            pd.DataFrame: æ¸…æ´—åçš„æ•°æ®
        """
        try:
            if df is None or df.empty:
                raise DataProcessError("è¾“å…¥æ•°æ®ä¸ºç©º")
            
            logger.info(f"å¼€å§‹æ¸…æ´—æ•°æ®ï¼ŒåŸå§‹æ•°æ® {len(df)} æ¡è®°å½•")
            
            # å¤åˆ¶æ•°æ®é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            cleaned_df = df.copy()
            
            # 1. å¤„ç†é‡å¤æ—¥æœŸ
            if cleaned_df.index.duplicated().any():
                logger.warning("å‘ç°é‡å¤æ—¥æœŸï¼Œä¿ç•™æœ€åä¸€æ¡è®°å½•")
                cleaned_df = cleaned_df[~cleaned_df.index.duplicated(keep='last')]
            
            # 2. æ’åº
            cleaned_df = cleaned_df.sort_index()
            
            # 3. å¤„ç†ç¼ºå¤±å€¼
            # å¯¹äºä»·æ ¼æ•°æ®ï¼Œä½¿ç”¨å‰å‘å¡«å……
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if col in cleaned_df.columns:
                    if cleaned_df[col].isnull().any():
                        logger.warning(f"å‘ç° {col} åˆ—ç¼ºå¤±å€¼ï¼Œä½¿ç”¨å‰å‘å¡«å……")
                        cleaned_df[col] = cleaned_df[col].fillna(method='ffill')
            
            # å¯¹äºæˆäº¤é‡ï¼Œä½¿ç”¨0å¡«å……
            if 'volume' in cleaned_df.columns:
                cleaned_df['volume'] = cleaned_df['volume'].fillna(0)
            
            # å¯¹äºåˆ†çº¢é…è‚¡æ•°æ®ï¼Œä½¿ç”¨0å¡«å……ï¼ˆè¡¨ç¤ºæ— åˆ†çº¢é…è‚¡ï¼‰
            for col in self.dividend_columns:
                if col in cleaned_df.columns:
                    cleaned_df[col] = cleaned_df[col].fillna(0)
                    # ç¡®ä¿åˆ†çº¢é…è‚¡æ•°æ®ä¸ºéè´Ÿæ•°
                    if col != 'allotment_price':  # é…è‚¡ä»·æ ¼å¯èƒ½ä¸º0ä½†ä¸åº”ä¸ºè´Ÿ
                        cleaned_df[col] = cleaned_df[col].clip(lower=0)
            
            # 4. å¤„ç†å¼‚å¸¸å€¼
            cleaned_df = self._handle_outliers(cleaned_df)
            
            # 5. éªŒè¯OHLCé€»è¾‘å¹¶ä¿®æ­£
            cleaned_df = self._fix_ohlc_logic(cleaned_df)
            
            # 6. æœ€ç»ˆéªŒè¯
            is_valid, issues = self.validate_data(cleaned_df)
            if not is_valid:
                logger.warning(f"æ¸…æ´—åæ•°æ®ä»å­˜åœ¨é—®é¢˜: {issues}")
            
            logger.info(f"æ•°æ®æ¸…æ´—å®Œæˆï¼Œæ¸…æ´—åæ•°æ® {len(cleaned_df)} æ¡è®°å½•")
            return cleaned_df
            
        except Exception as e:
            raise DataProcessError(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}") from e
    
    def resample_to_weekly(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å°†æ—¥çº¿æ•°æ®é‡é‡‡æ ·ä¸ºå‘¨çº¿æ•°æ®
        
        Args:
            df: æ—¥çº¿æ•°æ®
            
        Returns:
            pd.DataFrame: å‘¨çº¿æ•°æ®
        """
        try:
            if df is None or df.empty:
                raise DataProcessError("è¾“å…¥æ•°æ®ä¸ºç©º")
            
            logger.info(f"å°†æ—¥çº¿æ•°æ®é‡é‡‡æ ·ä¸ºå‘¨çº¿ï¼ŒåŸå§‹æ•°æ® {len(df)} æ¡è®°å½•")
            
            # ç¡®ä¿ç´¢å¼•æ˜¯æ—¥æœŸç±»å‹
            if not isinstance(df.index, pd.DatetimeIndex):
                raise DataProcessError("æ•°æ®ç´¢å¼•å¿…é¡»æ˜¯æ—¥æœŸç±»å‹")
            
            # å®šä¹‰é‡é‡‡æ ·è§„åˆ™
            agg_rules = {
                'open': 'first',    # å¼€ç›˜ä»·å–ç¬¬ä¸€ä¸ª
                'high': 'max',      # æœ€é«˜ä»·å–æœ€å¤§å€¼
                'low': 'min',       # æœ€ä½ä»·å–æœ€å°å€¼
                'close': 'last',    # æ”¶ç›˜ä»·å–æœ€åä¸€ä¸ª
                'volume': 'sum'     # æˆäº¤é‡æ±‚å’Œ
            }
            
            # æ·»åŠ å…¶ä»–å¯èƒ½å­˜åœ¨çš„åˆ—
            if 'amount' in df.columns:
                agg_rules['amount'] = 'sum'
            if 'turnover_rate' in df.columns:
                agg_rules['turnover_rate'] = 'mean'
            
            # é‡é‡‡æ ·åˆ°å‘¨çº¿ï¼ˆå‘¨äº”ä¸ºä¸€å‘¨ç»“æŸï¼‰
            weekly_df = df.resample('W-FRI').agg(agg_rules)
            
            # åˆ é™¤å…¨ä¸ºNaNçš„è¡Œï¼ˆå¯èƒ½æ˜¯æ²¡æœ‰äº¤æ˜“çš„å‘¨ï¼‰
            weekly_df = weekly_df.dropna(how='all')
            
            # å¤„ç†éƒ¨åˆ†NaNå€¼
            # å¯¹äºä»·æ ¼æ•°æ®ï¼Œä½¿ç”¨å‰å‘å¡«å……åå†åå‘å¡«å……
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if col in weekly_df.columns:
                    weekly_df[col] = weekly_df[col].ffill().bfill()
            
            # å¯¹äºæˆäº¤é‡ï¼Œä½¿ç”¨0å¡«å……
            if 'volume' in weekly_df.columns:
                weekly_df['volume'] = weekly_df['volume'].fillna(0)
            
            # å¯¹äºæˆäº¤é¢ï¼Œä½¿ç”¨0å¡«å……
            if 'amount' in weekly_df.columns:
                weekly_df['amount'] = weekly_df['amount'].fillna(0)
            
            # ç¡®ä¿OHLCé€»è¾‘æ­£ç¡®
            weekly_df = self._fix_ohlc_logic(weekly_df)
            
            # æœ€ç»ˆæ£€æŸ¥ï¼Œåˆ é™¤ä»»ä½•ä»ç„¶æœ‰NaNçš„è¡Œ
            weekly_df = weekly_df.dropna()
            
            logger.info(f"é‡é‡‡æ ·å®Œæˆï¼Œå‘¨çº¿æ•°æ® {len(weekly_df)} æ¡è®°å½•")
            return weekly_df
            
        except Exception as e:
            raise DataProcessError(f"é‡é‡‡æ ·å¤±è´¥: {str(e)}") from e
    
    def _handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†ç¼ºå¤±å€¼"""
        try:
            # å¯¹äºä»·æ ¼æ•°æ®ï¼Œä½¿ç”¨å‰å‘å¡«å……
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if col in df.columns:
                    # å…ˆå‰å‘å¡«å……ï¼Œå†åå‘å¡«å……
                    df[col] = df[col].ffill().bfill()
            
            # å¯¹äºæˆäº¤é‡ï¼Œä½¿ç”¨0å¡«å……ï¼ˆè¡¨ç¤ºæ— äº¤æ˜“ï¼‰
            if 'volume' in df.columns:
                df['volume'] = df['volume'].fillna(0)
            
            # å¯¹äºæˆäº¤é¢ï¼Œä½¿ç”¨0å¡«å……
            if 'amount' in df.columns:
                df['amount'] = df['amount'].fillna(0)
            
            # åˆ é™¤ä»ç„¶æœ‰ç¼ºå¤±å€¼çš„è¡Œ
            df = df.dropna()
            
            return df
            
        except Exception as e:
            raise DataProcessError(f"å¤„ç†ç¼ºå¤±å€¼å¤±è´¥: {str(e)}") from e
    
    def _handle_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†å¼‚å¸¸å€¼"""
        try:
            # å¤„ç†ä»·æ ¼å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨3å€æ ‡å‡†å·®è§„åˆ™ï¼‰
            price_columns = ['open', 'high', 'low', 'close']
            
            for col in price_columns:
                if col in df.columns and len(df) > 10:
                    # è®¡ç®—ä»·æ ¼å˜åŒ–ç‡
                    pct_change = df[col].pct_change().abs()
                    
                    # è¯†åˆ«å¼‚å¸¸å˜åŒ–ï¼ˆè¶…è¿‡3å€æ ‡å‡†å·®ï¼‰
                    mean_change = pct_change.mean()
                    std_change = pct_change.std()
                    threshold = mean_change + 3 * std_change
                    
                    outliers = pct_change > threshold
                    if outliers.any():
                        logger.warning(f"å‘ç° {outliers.sum()} ä¸ª {col} å¼‚å¸¸å€¼")
                        
                        # ç”¨å‰ä¸€ä¸ªæœ‰æ•ˆå€¼æ›¿æ¢å¼‚å¸¸å€¼
                        for idx in df.index[outliers]:
                            if idx != df.index[0]:  # ä¸æ˜¯ç¬¬ä¸€è¡Œ
                                prev_idx = df.index[df.index < idx][-1]
                                df.loc[idx, col] = df.loc[prev_idx, col]
            
            # å¤„ç†æˆäº¤é‡å¼‚å¸¸å€¼
            if 'volume' in df.columns and len(df) > 10:
                # æˆäº¤é‡ä¸èƒ½ä¸ºè´Ÿæ•°
                df.loc[df['volume'] < 0, 'volume'] = 0
                
                # å¤„ç†æç«¯å¤§çš„æˆäº¤é‡ï¼ˆè¶…è¿‡ä¸­ä½æ•°çš„100å€ï¼‰
                median_volume = df['volume'].median()
                if median_volume > 0:
                    extreme_volume = df['volume'] > median_volume * 100
                    if extreme_volume.any():
                        logger.warning(f"å‘ç° {extreme_volume.sum()} ä¸ªæˆäº¤é‡å¼‚å¸¸å€¼")
                        df.loc[extreme_volume, 'volume'] = median_volume
            
            return df
            
        except Exception as e:
            raise DataProcessError(f"å¤„ç†å¼‚å¸¸å€¼å¤±è´¥: {str(e)}") from e
    
    def _check_ohlc_logic(self, df: pd.DataFrame) -> int:
        """æ£€æŸ¥OHLCé€»è¾‘é”™è¯¯çš„è®°å½•æ•°"""
        try:
            if not all(col in df.columns for col in ['open', 'high', 'low', 'close']):
                return 0
            
            # æ£€æŸ¥ high >= max(open, close) å’Œ low <= min(open, close)
            invalid_high = df['high'] < df[['open', 'close']].max(axis=1)
            invalid_low = df['low'] > df[['open', 'close']].min(axis=1)
            
            return (invalid_high | invalid_low).sum()
            
        except Exception:
            return 0
    
    def _fix_ohlc_logic(self, df: pd.DataFrame) -> pd.DataFrame:
        """ä¿®æ­£OHLCé€»è¾‘é”™è¯¯"""
        try:
            if not all(col in df.columns for col in ['open', 'high', 'low', 'close']):
                return df
            
            # ä¿®æ­£æœ€é«˜ä»·ï¼šç¡®ä¿ high >= max(open, close)
            max_oc = df[['open', 'close']].max(axis=1)
            df.loc[df['high'] < max_oc, 'high'] = max_oc
            
            # ä¿®æ­£æœ€ä½ä»·ï¼šç¡®ä¿ low <= min(open, close)
            min_oc = df[['open', 'close']].min(axis=1)
            df.loc[df['low'] > min_oc, 'low'] = min_oc
            
            return df
            
        except Exception as e:
            logger.warning(f"ä¿®æ­£OHLCé€»è¾‘å¤±è´¥: {str(e)}")
            return df
    
    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ - å¸¦è¯¦ç»†è°ƒè¯•æ—¥å¿—
        
        Args:
            df: åŒ…å«OHLCVæ•°æ®çš„DataFrame
            
        Returns:
            pd.DataFrame: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„æ•°æ®
        """
        try:
            if df is None or df.empty:
                raise DataProcessError("è¾“å…¥æ•°æ®ä¸ºç©º")
            
            logger.info("=" * 60)
            logger.info("ğŸ” å¼€å§‹è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ - è¯¦ç»†è°ƒè¯•æ¨¡å¼")
            logger.info("=" * 60)
            
            # å¤åˆ¶æ•°æ®é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            result_df = df.copy()
            
            # è¾“å…¥æ•°æ®æ£€æŸ¥
            logger.info(f"ğŸ“Š è¾“å…¥æ•°æ®æ¦‚å†µ:")
            logger.info(f"   - æ•°æ®è¡Œæ•°: {len(result_df)}")
            logger.info(f"   - æ•°æ®åˆ—æ•°: {len(result_df.columns)}")
            logger.info(f"   - æ•°æ®èŒƒå›´: {result_df.index.min()} åˆ° {result_df.index.max()}")
            logger.info(f"   - æ”¶ç›˜ä»·èŒƒå›´: {result_df['close'].min():.4f} - {result_df['close'].max():.4f}")
            logger.info(f"   - æ”¶ç›˜ä»·NaNæ•°é‡: {result_df['close'].isna().sum()}")
            
            # è®¡ç®—RSI
            logger.info("\nğŸ”„ è®¡ç®—RSIæŒ‡æ ‡...")
            result_df['rsi'] = self._calculate_rsi_debug(result_df['close'])
            
            # è®¡ç®—EMAï¼ˆä½¿ç”¨åˆ†å±‚æ ‡å‡†åŒ–ç­–ç•¥ï¼‰
            logger.info("\nğŸ”„ è®¡ç®—EMAæŒ‡æ ‡...")
            logger.info("   - è®¡ç®—EMA20...")
            ema_20_data = self._calculate_ema_debug(result_df['close'], 20)
            result_df['ema_20'] = ema_20_data
            logger.info(f"   - EMA20 NaNæ•°é‡: {result_df['ema_20'].isna().sum()}")
            logger.info(f"   - EMA20 æœ€å5ä¸ªå€¼: {result_df['ema_20'].tail().values}")
            
            logger.info("   - è®¡ç®—EMA50...")
            ema_50_data = self._calculate_ema_debug(result_df['close'], 50)
            result_df['ema_50'] = ema_50_data
            logger.info(f"   - EMA50 NaNæ•°é‡: {result_df['ema_50'].isna().sum()}")
            logger.info(f"   - EMA50 æœ€å5ä¸ªå€¼: {result_df['ema_50'].tail().values}")
            
            logger.info("   - è®¡ç®—EMA60...")
            ema_60_data = self._calculate_ema_debug(result_df['close'], 60)
            result_df['ema_60'] = ema_60_data
            logger.info(f"   - EMA60 NaNæ•°é‡: {result_df['ema_60'].isna().sum()}")
            logger.info(f"   - EMA60 æœ€å5ä¸ªå€¼: {result_df['ema_60'].tail().values}")
            
            # è®¡ç®—MACD
            logger.info("\nğŸ”„ è®¡ç®—MACDæŒ‡æ ‡...")
            macd_data = self._calculate_macd_debug(result_df['close'])
            result_df['macd'] = macd_data['macd']
            result_df['macd_signal'] = macd_data['signal']
            result_df['macd_histogram'] = macd_data['histogram']
            
            # è®¡ç®—å¸ƒæ—å¸¦
            logger.info("\nğŸ”„ è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡...")
            bb_data = self._calculate_bollinger_bands_debug(result_df['close'])
            result_df['bb_upper'] = bb_data['upper']
            result_df['bb_middle'] = bb_data['middle']
            result_df['bb_lower'] = bb_data['lower']
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿ - ä½¿ç”¨TA-Lib SMA
            logger.info("\nğŸ”„ è®¡ç®—ç§»åŠ¨å¹³å‡çº¿...")
            
            # ä½¿ç”¨TA-Libè®¡ç®—SMA
            from indicators.trend import calculate_sma
            
            logger.info("   - è®¡ç®—MA5...")
            result_df['ma_5'] = calculate_sma(result_df['close'], 5)
            logger.info(f"   - MA5 NaNæ•°é‡: {result_df['ma_5'].isna().sum()}")
            
            # æ£€æŸ¥MA5å›æµ‹æœŸé—´æœ‰æ•ˆæ€§
            if len(result_df['ma_5']) >= 126:
                backtest_ma5 = result_df['ma_5'].iloc[125:]
                backtest_nan = backtest_ma5.isna().sum()
                if backtest_nan == 0:
                    logger.info(f"   - âœ… å›æµ‹æœŸé—´MA5 100%æœ‰æ•ˆ")
                else:
                    logger.warning(f"   - âš ï¸ å›æµ‹æœŸé—´MA5å­˜åœ¨{backtest_nan}ä¸ªNaN")
            
            logger.info("   - è®¡ç®—MA10...")
            result_df['ma_10'] = calculate_sma(result_df['close'], 10)
            logger.info(f"   - MA10 NaNæ•°é‡: {result_df['ma_10'].isna().sum()}")
            
            # æ£€æŸ¥MA10å›æµ‹æœŸé—´æœ‰æ•ˆæ€§
            if len(result_df['ma_10']) >= 126:
                backtest_ma10 = result_df['ma_10'].iloc[125:]
                backtest_nan = backtest_ma10.isna().sum()
                if backtest_nan == 0:
                    logger.info(f"   - âœ… å›æµ‹æœŸé—´MA10 100%æœ‰æ•ˆ")
                else:
                    logger.warning(f"   - âš ï¸ å›æµ‹æœŸé—´MA10å­˜åœ¨{backtest_nan}ä¸ªNaN")
            
            logger.info("   - è®¡ç®—MA20...")
            result_df['ma_20'] = calculate_sma(result_df['close'], 20)
            logger.info(f"   - MA20 NaNæ•°é‡: {result_df['ma_20'].isna().sum()}")
            
            # æ£€æŸ¥MA20å›æµ‹æœŸé—´æœ‰æ•ˆæ€§
            if len(result_df['ma_20']) >= 126:
                backtest_ma20 = result_df['ma_20'].iloc[125:]
                backtest_nan = backtest_ma20.isna().sum()
                if backtest_nan == 0:
                    logger.info(f"   - âœ… å›æµ‹æœŸé—´MA20 100%æœ‰æ•ˆ")
                else:
                    logger.warning(f"   - âš ï¸ å›æµ‹æœŸé—´MA20å­˜åœ¨{backtest_nan}ä¸ªNaN")
            
            # è®¡ç®—æˆäº¤é‡æŒ‡æ ‡
            if 'volume' in result_df.columns:
                logger.info("\nğŸ”„ è®¡ç®—æˆäº¤é‡æŒ‡æ ‡...")
                logger.info(f"   - æˆäº¤é‡NaNæ•°é‡: {result_df['volume'].isna().sum()}")
                logger.info(f"   - æˆäº¤é‡èŒƒå›´: {result_df['volume'].min()} - {result_df['volume'].max()}")
                
                # ä½¿ç”¨4å‘¨å‡é‡ï¼ˆç­–ç•¥æ–‡æ¡£è¦æ±‚ï¼šæç«¯ä»·æ ¼é‡èƒ½åˆ¤æ–­ä½¿ç”¨4å‘¨å‡é‡ï¼‰
                result_df['volume_ma'] = result_df['volume'].rolling(window=4).mean()
                logger.info(f"   - æˆäº¤é‡MA4 NaNæ•°é‡: {result_df['volume_ma'].isna().sum()}")
                
                # æ£€æŸ¥é™¤é›¶æƒ…å†µ
                zero_volume_ma = (result_df['volume_ma'] == 0).sum()
                logger.info(f"   - æˆäº¤é‡MA4ä¸º0çš„æ•°é‡: {zero_volume_ma}")
                
                result_df['volume_ratio'] = result_df['volume'] / result_df['volume_ma']
                logger.info(f"   - æˆäº¤é‡æ¯”ç‡ NaNæ•°é‡: {result_df['volume_ratio'].isna().sum()}")
                logger.info(f"   - æˆäº¤é‡æ¯”ç‡ æ— ç©·å¤§æ•°é‡: {np.isinf(result_df['volume_ratio']).sum()}")
            
            # æœ€ç»ˆç»Ÿè®¡
            logger.info("\nğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆç»Ÿè®¡:")
            logger.info("-" * 40)
            for col in result_df.columns:
                if col not in ['open', 'high', 'low', 'close', 'volume']:
                    nan_count = result_df[col].isna().sum()
                    inf_count = np.isinf(result_df[col]).sum() if result_df[col].dtype in ['float64', 'float32'] else 0
                    logger.info(f"   {col:15}: NaN={nan_count:3d}, Inf={inf_count:3d}")
            
            logger.info("=" * 60)
            
            return result_df
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            raise DataProcessError(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {str(e)}") from e
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡ - ä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨å…¨éƒ¨å†å²æ•°æ®"""
        try:
            # v4.2ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨å…¨éƒ¨å†å²æ•°æ®è®¡ç®—RSIï¼Œä¸ä½¿ç”¨å¤æ‚çš„æ»šåŠ¨çª—å£
            # è¿™æ ·å¯ä»¥å……åˆ†åˆ©ç”¨å·²è·å–çš„125å‘¨å†å²æ•°æ®
            from indicators.momentum import calculate_rsi
            rsi = calculate_rsi(prices, period)
            
            return rsi
            
        except Exception as e:
            raise DataProcessError(f"RSIè®¡ç®—å¤±è´¥: {str(e)}") from e
    
    def _calculate_ema_debug(self, prices: pd.Series, period: int) -> pd.Series:
        """è®¡ç®—EMAæŒ‡æ ‡ - ä½¿ç”¨TA-Libç¡®ä¿å›æµ‹æœŸé—´100%æœ‰æ•ˆ"""
        try:
            logger.info(f"   - EMA{period}è®¡ç®—è¾“å…¥: ä»·æ ¼åºåˆ—é•¿åº¦={len(prices)}, å‘¨æœŸ={period}")
            logger.info(f"   - ä»·æ ¼åºåˆ—NaNæ•°é‡: {prices.isna().sum()}")
            
            # v4.2ä¿®å¤ï¼šä½¿ç”¨TA-Libè®¡ç®—EMAï¼Œä½†ç¡®ä¿å›æµ‹æœŸé—´100%æœ‰æ•ˆ
            # ç­–ç•¥ï¼šTA-Libéœ€è¦é¢„çƒ­æœŸï¼Œä½†æˆ‘ä»¬æœ‰125å‘¨å†å²æ•°æ®è¶³å¤Ÿè¦†ç›–é¢„çƒ­æœŸ
            from indicators.trend import calculate_ema
            
            # ä½¿ç”¨TA-Libè®¡ç®—EMAï¼ˆä¼šæœ‰å‰period-1ä¸ªNaNï¼‰
            ema_full = calculate_ema(prices, period)
            
            # æ£€æŸ¥å®é™…çš„NaNåˆ†å¸ƒ
            nan_count = ema_full.isna().sum()
            valid_count = len(ema_full) - nan_count
            valid_rate = (valid_count / len(ema_full)) * 100
            
            logger.info(f"   - ä½¿ç”¨TA-Libè®¡ç®—EMA{period}")
            logger.info(f"   - æ€»æ•°æ®ç‚¹: {len(ema_full)}")
            logger.info(f"   - NaNæ•°é‡: {nan_count} (å‰{nan_count}ä¸ªç‚¹)")
            logger.info(f"   - æœ‰æ•ˆæ•°æ®ç‚¹: {valid_count}")
            logger.info(f"   - æœ‰æ•ˆç‡: {valid_rate:.2f}%")
            
            # å¯¹äº125å‘¨å†å²æ•°æ®ï¼Œå‰19ä¸ªç‚¹ä¸ºNaNï¼ˆEMA20ï¼‰ï¼Œä½†å›æµ‹æœŸé—´ï¼ˆç¬¬126ä¸ªç‚¹å¼€å§‹ï¼‰100%æœ‰æ•ˆ
            if len(ema_full) >= 126:  # å¦‚æœæœ‰è¶³å¤Ÿçš„æ•°æ®
                backtest_period = ema_full.iloc[125:]  # å›æµ‹æœŸé—´æ•°æ®
                backtest_nan = backtest_period.isna().sum()
                logger.info(f"   - å›æµ‹æœŸé—´({len(backtest_period)}ä¸ªç‚¹): NaNæ•°é‡={backtest_nan}")
                if backtest_nan == 0:
                    logger.info(f"   - âœ… å›æµ‹æœŸé—´EMA{period} 100%æœ‰æ•ˆ")
                else:
                    logger.warning(f"   - âš ï¸ å›æµ‹æœŸé—´EMA{period}å­˜åœ¨{backtest_nan}ä¸ªNaN")
            
            logger.info(f"   - EMA{period} æœ€å5ä¸ªå€¼: {ema_full.tail().values}")
            return ema_full
            
        except Exception as e:
            logger.error(f"   - EMA{period}è®¡ç®—å¤±è´¥: {str(e)}")
            raise DataProcessError(f"EMA{period}è®¡ç®—å¤±è´¥: {str(e)}") from e
    
    def _calculate_rsi_debug(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡ - ä½¿ç”¨TA-Libå®ç°ï¼Œç¡®ä¿å›æµ‹æœŸé—´100%æœ‰æ•ˆ"""
        try:
            logger.info(f"   - RSIè®¡ç®—è¾“å…¥: ä»·æ ¼åºåˆ—é•¿åº¦={len(prices)}, å‘¨æœŸ={period}")
            logger.info(f"   - ä»·æ ¼åºåˆ—NaNæ•°é‡: {prices.isna().sum()}")
            
            # ä½¿ç”¨TA-Libè®¡ç®—RSIï¼Œå……åˆ†åˆ©ç”¨125å‘¨å†å²æ•°æ®
            from indicators.momentum import calculate_rsi
            rsi = calculate_rsi(prices, period)
            
            logger.info(f"   - ä½¿ç”¨TA-Libè®¡ç®—RSI{period}ï¼Œåˆ©ç”¨{len(prices)}å‘¨å†å²æ•°æ®")
            logger.info(f"   - RSI NaNæ•°é‡: {rsi.isna().sum()}")
            logger.info(f"   - RSI é¢„æœŸå‰{period}ä¸ªç‚¹ä¸ºNaNï¼Œè¿™æ˜¯TA-Libçš„æ­£å¸¸è¡Œä¸º")
            
            # æ£€æŸ¥å›æµ‹æœŸé—´æœ‰æ•ˆæ€§
            if len(rsi) >= 126:
                backtest_period = rsi.iloc[125:]
                backtest_nan = backtest_period.isna().sum()
                logger.info(f"   - å›æµ‹æœŸé—´({len(backtest_period)}ä¸ªç‚¹): NaNæ•°é‡={backtest_nan}")
                if backtest_nan == 0:
                    logger.info(f"   - âœ… å›æµ‹æœŸé—´RSI{period} 100%æœ‰æ•ˆ")
                else:
                    logger.warning(f"   - âš ï¸ å›æµ‹æœŸé—´RSI{period}å­˜åœ¨{backtest_nan}ä¸ªNaN")
            
            logger.info(f"   - RSI æœ€å5ä¸ªå€¼: {rsi.tail().values}")
            return rsi
            
        except Exception as e:
            logger.error(f"   - RSIè®¡ç®—å¤±è´¥: {str(e)}")
            raise DataProcessError(f"RSIè®¡ç®—å¤±è´¥: {str(e)}") from e
    
    def _calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> dict:
        """è®¡ç®—MACDæŒ‡æ ‡ - ä½¿ç”¨TA-Libç¡®ä¿å‡†ç¡®æ€§"""
        try:
            # v4.2ä¿®å¤ï¼šä½¿ç”¨TA-Libè®¡ç®—MACDï¼Œç¡®ä¿è®¡ç®—å‡†ç¡®æ€§
            # è™½ç„¶ä¼šæœ‰é¢„çƒ­æœŸNaNï¼Œä½†å›æµ‹æœŸé—´ï¼ˆåŸºäº125å‘¨å†å²æ•°æ®ï¼‰ä¼š100%æœ‰æ•ˆ
            from indicators.momentum import calculate_macd
            
            macd_result = calculate_macd(prices, fast, slow, signal)
            
            return {
                'macd': macd_result['dif'],
                'signal': macd_result['dea'],
                'histogram': macd_result['hist']
            }
                
        except Exception:
            return {
                'macd': pd.Series(index=prices.index, dtype=float),
                'signal': pd.Series(index=prices.index, dtype=float),
                'histogram': pd.Series(index=prices.index, dtype=float)
            }
    
    def _calculate_macd_debug(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> dict:
        """è®¡ç®—MACDæŒ‡æ ‡ - ä½¿ç”¨TA-Libå®ç°ï¼Œç¡®ä¿å›æµ‹æœŸé—´100%æœ‰æ•ˆ"""
        try:
            logger.info(f"   - MACDè®¡ç®—è¾“å…¥: ä»·æ ¼åºåˆ—é•¿åº¦={len(prices)}, å¿«çº¿={fast}, æ…¢çº¿={slow}, ä¿¡å·çº¿={signal}")
            
            from indicators.momentum import calculate_macd
            macd_result = calculate_macd(prices, fast, slow, signal)
            
            logger.info(f"   - ä½¿ç”¨TA-Libè®¡ç®—MACDæˆåŠŸ")
            logger.info(f"   - MACDçº¿ NaNæ•°é‡: {macd_result['dif'].isna().sum()}")
            logger.info(f"   - MACDä¿¡å·çº¿ NaNæ•°é‡: {macd_result['dea'].isna().sum()}")
            logger.info(f"   - MACDæŸ±çŠ¶å›¾ NaNæ•°é‡: {macd_result['hist'].isna().sum()}")
            
            # æ£€æŸ¥å›æµ‹æœŸé—´æœ‰æ•ˆæ€§
            if len(macd_result['dif']) >= 126:
                backtest_dif = macd_result['dif'].iloc[125:]
                backtest_nan = backtest_dif.isna().sum()
                logger.info(f"   - å›æµ‹æœŸé—´({len(backtest_dif)}ä¸ªç‚¹): MACDçº¿ NaNæ•°é‡={backtest_nan}")
                if backtest_nan == 0:
                    logger.info(f"   - âœ… å›æµ‹æœŸé—´MACD 100%æœ‰æ•ˆ")
                else:
                    logger.warning(f"   - âš ï¸ å›æµ‹æœŸé—´MACDå­˜åœ¨{backtest_nan}ä¸ªNaN")
            
            logger.info(f"   - MACDçº¿èŒƒå›´: {macd_result['dif'].min():.6f} - {macd_result['dif'].max():.6f}")
            logger.info(f"   - MACDæŸ±çŠ¶å›¾èŒƒå›´: {macd_result['hist'].min():.6f} - {macd_result['hist'].max():.6f}")
            
            return {
                'macd': macd_result['dif'],
                'signal': macd_result['dea'],
                'histogram': macd_result['hist']
            }
            
        except Exception as e:
            logger.error(f"   - MACDè®¡ç®—å¤±è´¥: {str(e)}")
            raise DataProcessError(f"MACDè®¡ç®—å¤±è´¥: {str(e)}") from e
    
    def _calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: float = 2) -> dict:
        """è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡ - ä½¿ç”¨TA-Libå®ç°"""
        try:
            # ä½¿ç”¨TA-Lib volatility.pyæ¨¡å—è®¡ç®—å¸ƒæ—å¸¦
            from indicators.volatility import calculate_bollinger_bands
            return calculate_bollinger_bands(prices, period, std_dev)
                
        except Exception as e:
            raise DataProcessError(f"å¸ƒæ—å¸¦è®¡ç®—å¤±è´¥: {str(e)}") from e
    
    def _calculate_bollinger_bands_debug(self, prices: pd.Series, period: int = 20, std_dev: float = 2) -> dict:
        """è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡ - ä½¿ç”¨TA-Libå®ç°ï¼Œç¡®ä¿å›æµ‹æœŸé—´100%æœ‰æ•ˆ"""
        try:
            logger.info(f"   - å¸ƒæ—å¸¦è®¡ç®—è¾“å…¥: ä»·æ ¼åºåˆ—é•¿åº¦={len(prices)}, å‘¨æœŸ={period}, æ ‡å‡†å·®å€æ•°={std_dev}")
            
            # ä½¿ç”¨TA-Lib volatility.pyæ¨¡å—è®¡ç®—å¸ƒæ—å¸¦
            from indicators.volatility import calculate_bollinger_bands
            bb_result = calculate_bollinger_bands(prices, period, std_dev)
            
            logger.info(f"   - ä½¿ç”¨TA-Libè®¡ç®—å¸ƒæ—å¸¦æˆåŠŸ")
            logger.info(f"   - ä¸Šè½¨ NaNæ•°é‡: {bb_result['upper'].isna().sum()}")
            logger.info(f"   - ä¸­è½¨ NaNæ•°é‡: {bb_result['middle'].isna().sum()}")
            logger.info(f"   - ä¸‹è½¨ NaNæ•°é‡: {bb_result['lower'].isna().sum()}")
            
            # æ£€æŸ¥å›æµ‹æœŸé—´æœ‰æ•ˆæ€§
            if len(bb_result['upper']) >= 126:
                backtest_upper = bb_result['upper'].iloc[125:]
                backtest_nan = backtest_upper.isna().sum()
                logger.info(f"   - å›æµ‹æœŸé—´({len(backtest_upper)}ä¸ªç‚¹): NaNæ•°é‡={backtest_nan}")
                if backtest_nan == 0:
                    logger.info(f"   - âœ… å›æµ‹æœŸé—´å¸ƒæ—å¸¦ 100%æœ‰æ•ˆ")
                else:
                    logger.warning(f"   - âš ï¸ å›æµ‹æœŸé—´å¸ƒæ—å¸¦å­˜åœ¨{backtest_nan}ä¸ªNaN")
            
            return bb_result
            
        except Exception as e:
            logger.error(f"   - å¸ƒæ—å¸¦è®¡ç®—å¤±è´¥: {str(e)}")
            raise DataProcessError(f"å¸ƒæ—å¸¦è®¡ç®—å¤±è´¥: {str(e)}") from e

    def get_data_summary(self, df: pd.DataFrame) -> dict:
        """
        è·å–æ•°æ®æ‘˜è¦ä¿¡æ¯
        
        Args:
            df: æ•°æ®DataFrame
            
        Returns:
            dict: æ•°æ®æ‘˜è¦
        """
        try:
            if df is None or df.empty:
                return {"error": "æ•°æ®ä¸ºç©º"}
            
            summary = {
                "è®°å½•æ•°": len(df),
                "å¼€å§‹æ—¥æœŸ": df.index.min().strftime('%Y-%m-%d') if not df.empty else None,
                "ç»“æŸæ—¥æœŸ": df.index.max().strftime('%Y-%m-%d') if not df.empty else None,
                "åˆ—æ•°": len(df.columns),
                "åˆ—å": list(df.columns),
                "ç¼ºå¤±å€¼": df.isnull().sum().to_dict(),
                "æ•°æ®ç±»å‹": df.dtypes.to_dict()
            }
            
            # æ·»åŠ ä»·æ ¼ç»Ÿè®¡ä¿¡æ¯
            if 'close' in df.columns:
                summary["æ”¶ç›˜ä»·ç»Ÿè®¡"] = {
                    "æœ€å°å€¼": float(df['close'].min()),
                    "æœ€å¤§å€¼": float(df['close'].max()),
                    "å¹³å‡å€¼": float(df['close'].mean()),
                    "æ ‡å‡†å·®": float(df['close'].std())
                }
            
            return summary
            
        except Exception as e:
            return {"error": f"ç”Ÿæˆæ•°æ®æ‘˜è¦å¤±è´¥: {str(e)}"}
    
    def process_dividend_events(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å¤„ç†åˆ†çº¢é…è‚¡äº‹ä»¶ï¼Œè®¡ç®—å¯¹è‚¡ä»·å’ŒæŒä»“çš„å½±å“
        
        Args:
            df: åŒ…å«åˆ†çº¢é…è‚¡ä¿¡æ¯çš„æ•°æ®
            
        Returns:
            pd.DataFrame: å¤„ç†åçš„æ•°æ®ï¼ŒåŒ…å«é™¤æƒé™¤æ¯è°ƒæ•´ä¿¡æ¯
        """
        try:
            if df is None or df.empty:
                return df
            
            processed_df = df.copy()
            
            # æ·»åŠ é™¤æƒé™¤æ¯æ ‡è®°åˆ—
            processed_df['has_dividend'] = (processed_df.get('dividend_amount', 0) > 0)
            processed_df['has_allotment'] = (processed_df.get('allotment_ratio', 0) > 0)
            processed_df['has_bonus'] = (processed_df.get('bonus_ratio', 0) > 0)
            processed_df['has_transfer'] = (processed_df.get('transfer_ratio', 0) > 0)
            
            # è®¡ç®—é™¤æƒé™¤æ¯è°ƒæ•´å› å­
            processed_df['rights_factor'] = 1.0  # é™¤æƒå› å­
            processed_df['dividend_factor'] = 0.0  # åˆ†çº¢å› å­
            
            for idx in processed_df.index:
                row = processed_df.loc[idx]
                
                # è®¡ç®—é™¤æƒå› å­ï¼ˆé€è‚¡ã€è½¬å¢ã€é…è‚¡çš„å½±å“ï¼‰
                bonus_ratio = row.get('bonus_ratio', 0) / 10  # 10é€Xè½¬æ¢ä¸ºæ¯”ä¾‹
                transfer_ratio = row.get('transfer_ratio', 0) / 10  # 10è½¬Xè½¬æ¢ä¸ºæ¯”ä¾‹
                allotment_ratio = row.get('allotment_ratio', 0) / 10  # 10é…Xè½¬æ¢ä¸ºæ¯”ä¾‹
                
                # é™¤æƒå› å­ = 1 / (1 + é€è‚¡æ¯”ä¾‹ + è½¬å¢æ¯”ä¾‹ + é…è‚¡æ¯”ä¾‹)
                rights_factor = 1.0 / (1.0 + bonus_ratio + transfer_ratio + allotment_ratio)
                processed_df.loc[idx, 'rights_factor'] = rights_factor
                
                # åˆ†çº¢å› å­ï¼ˆæ¯è‚¡åˆ†çº¢é‡‘é¢ï¼‰
                dividend_amount = row.get('dividend_amount', 0)
                processed_df.loc[idx, 'dividend_factor'] = dividend_amount
                
                if (bonus_ratio > 0 or transfer_ratio > 0 or allotment_ratio > 0 or dividend_amount > 0):
                    logger.debug(f"é™¤æƒé™¤æ¯äº‹ä»¶ {idx.date()}: "
                               f"é€è‚¡{bonus_ratio:.3f}, è½¬å¢{transfer_ratio:.3f}, "
                               f"é…è‚¡{allotment_ratio:.3f}, åˆ†çº¢{dividend_amount:.3f}")
            
            logger.info(f"å¤„ç†åˆ†çº¢é…è‚¡äº‹ä»¶å®Œæˆï¼Œå…±å‘ç° "
                       f"{processed_df['has_dividend'].sum()} ä¸ªåˆ†çº¢äº‹ä»¶ï¼Œ"
                       f"{processed_df['has_allotment'].sum()} ä¸ªé…è‚¡äº‹ä»¶ï¼Œ"
                       f"{processed_df['has_bonus'].sum()} ä¸ªé€è‚¡äº‹ä»¶ï¼Œ"
                       f"{processed_df['has_transfer'].sum()} ä¸ªè½¬å¢äº‹ä»¶")
            
            return processed_df
            
        except Exception as e:
            logger.error(f"å¤„ç†åˆ†çº¢é…è‚¡äº‹ä»¶å¤±è´¥: {str(e)}")
            return df

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')
    test_data = pd.DataFrame({
        'open': np.random.uniform(10, 20, len(dates)),
        'high': np.random.uniform(15, 25, len(dates)),
        'low': np.random.uniform(5, 15, len(dates)),
        'close': np.random.uniform(10, 20, len(dates)),
        'volume': np.random.randint(1000, 10000, len(dates))
    }, index=dates)
    
    # æ·»åŠ ä¸€äº›å¼‚å¸¸å€¼è¿›è¡Œæµ‹è¯•
    test_data.loc[test_data.index[10], 'high'] = test_data.loc[test_data.index[10], 'low'] - 1  # OHLCé€»è¾‘é”™è¯¯
    test_data.loc[test_data.index[20:25], 'close'] = np.nan  # ç¼ºå¤±å€¼
    
    processor = DataProcessor()
    
    # æµ‹è¯•æ•°æ®éªŒè¯
    is_valid, issues = processor.validate_data(test_data)
    print(f"æ•°æ®éªŒè¯ç»“æœ: {is_valid}")
    if issues:
        print(f"å‘ç°é—®é¢˜: {issues}")
    
    # æµ‹è¯•æ•°æ®æ¸…æ´—
    cleaned_data = processor.clean_data(test_data)
    print(f"æ¸…æ´—å‰: {len(test_data)} æ¡è®°å½•")
    print(f"æ¸…æ´—å: {len(cleaned_data)} æ¡è®°å½•")
    
    # æµ‹è¯•é‡é‡‡æ ·
    weekly_data = processor.resample_to_weekly(cleaned_data)
    print(f"å‘¨çº¿æ•°æ®: {len(weekly_data)} æ¡è®°å½•")
    
    # æµ‹è¯•æ•°æ®æ‘˜è¦
    summary = processor.get_data_summary(weekly_data)
    print(f"æ•°æ®æ‘˜è¦: {summary}")