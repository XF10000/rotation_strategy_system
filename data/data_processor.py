"""
æ•°æ®é¢„å¤„ç†å™¨æ¨¡å—
æä¾›æ•°æ®éªŒè¯ã€æ¸…æ´—å’Œæ ¼å¼è½¬æ¢åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import logging
from typing import Tuple, List, Optional

from .exceptions import DataProcessError

logger = logging.getLogger(__name__)

class DataProcessor:
    """æ•°æ®é¢„å¤„ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨"""
        self.required_columns = ['open', 'high', 'low', 'close', 'volume']
        logger.info("åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨")
    
    def validate_data(self, df: pd.DataFrame) -> Tuple[bool, List[str]]:
        """
        éªŒè¯æ•°æ®å®Œæ•´æ€§
        
        Args:
            df: åŸå§‹æ•°æ®
            
        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦æœ‰æ•ˆ, é—®é¢˜åˆ—è¡¨)
        """
        issues = []
        
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
            if df is None or df.empty:
                issues.append("æ•°æ®ä¸ºç©º")
                return False, issues
            
            # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            missing_columns = [col for col in self.required_columns if col not in df.columns]
            if missing_columns:
                issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            for col in ['open', 'high', 'low', 'close']:
                if col in df.columns and not pd.api.types.is_numeric_dtype(df[col]):
                    issues.append(f"åˆ— {col} ä¸æ˜¯æ•°å€¼ç±»å‹")
            
            # æ£€æŸ¥OHLCé€»è¾‘
            if all(col in df.columns for col in ['open', 'high', 'low', 'close']):
                invalid_ohlc = self._check_ohlc_logic(df)
                if invalid_ohlc > 0:
                    issues.append(f"å‘ç° {invalid_ohlc} æ¡OHLCé€»è¾‘é”™è¯¯çš„è®°å½•")
            
            # æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹
            if not df.empty:
                missing_ratio = df.isnull().sum().sum() / (len(df) * len(df.columns))
                if missing_ratio > 0.05:  # è¶…è¿‡5%çš„ç¼ºå¤±å€¼
                    issues.append(f"ç¼ºå¤±å€¼æ¯”ä¾‹è¿‡é«˜: {missing_ratio:.2%}")
            
            # æ£€æŸ¥å¼‚å¸¸å€¼
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if col in df.columns:
                    if (df[col] <= 0).any():
                        issues.append(f"åˆ— {col} å­˜åœ¨éæ­£æ•°å€¼")
                    
                    # æ£€æŸ¥æç«¯å€¼ï¼ˆä»·æ ¼å˜åŒ–è¶…è¿‡50%ï¼‰
                    if len(df) > 1:
                        pct_change = df[col].pct_change().abs()
                        extreme_changes = (pct_change > 0.5).sum()
                        if extreme_changes > 0:
                            issues.append(f"åˆ— {col} å­˜åœ¨ {extreme_changes} ä¸ªæç«¯å˜åŒ–å€¼")
            
            # æ£€æŸ¥æˆäº¤é‡
            if 'volume' in df.columns:
                if (df['volume'] < 0).any():
                    issues.append("æˆäº¤é‡å­˜åœ¨è´Ÿæ•°")
            
            # æ£€æŸ¥æ—¥æœŸç´¢å¼•
            if not isinstance(df.index, pd.DatetimeIndex):
                issues.append("ç´¢å¼•ä¸æ˜¯æ—¥æœŸç±»å‹")
            elif not df.index.is_monotonic_increasing:
                issues.append("æ—¥æœŸç´¢å¼•ä¸æ˜¯é€’å¢é¡ºåº")
            
            is_valid = len(issues) == 0
            return is_valid, issues
            
        except Exception as e:
            issues.append(f"æ•°æ®éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return False, issues
    
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ¸…æ´—æ•°æ®ï¼ˆå¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ç­‰ï¼‰
        
        Args:
            df: åŸå§‹æ•°æ®
            
        Returns:
            pd.DataFrame: æ¸…æ´—åçš„æ•°æ®
        """
        try:
            if df is None or df.empty:
                raise DataProcessError("è¾“å…¥æ•°æ®ä¸ºç©º")
            
            logger.info(f"å¼€å§‹æ¸…æ´—æ•°æ®ï¼ŒåŸå§‹æ•°æ® {len(df)} æ¡è®°å½•")
            
            # å¤åˆ¶æ•°æ®é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            cleaned_df = df.copy()
            
            # 1. å¤„ç†é‡å¤æ—¥æœŸ
            if cleaned_df.index.duplicated().any():
                logger.warning("å‘ç°é‡å¤æ—¥æœŸï¼Œä¿ç•™æœ€åä¸€æ¡è®°å½•")
                cleaned_df = cleaned_df[~cleaned_df.index.duplicated(keep='last')]
            
            # 2. æ’åº
            cleaned_df = cleaned_df.sort_index()
            
            # 3. å¤„ç†ç¼ºå¤±å€¼
            cleaned_df = self._handle_missing_values(cleaned_df)
            
            # 4. å¤„ç†å¼‚å¸¸å€¼
            cleaned_df = self._handle_outliers(cleaned_df)
            
            # 5. éªŒè¯OHLCé€»è¾‘å¹¶ä¿®æ­£
            cleaned_df = self._fix_ohlc_logic(cleaned_df)
            
            # 6. æœ€ç»ˆéªŒè¯
            is_valid, issues = self.validate_data(cleaned_df)
            if not is_valid:
                logger.warning(f"æ¸…æ´—åæ•°æ®ä»å­˜åœ¨é—®é¢˜: {issues}")
            
            logger.info(f"æ•°æ®æ¸…æ´—å®Œæˆï¼Œæ¸…æ´—åæ•°æ® {len(cleaned_df)} æ¡è®°å½•")
            return cleaned_df
            
        except Exception as e:
            raise DataProcessError(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}") from e
    
    def resample_to_weekly(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å°†æ—¥çº¿æ•°æ®é‡é‡‡æ ·ä¸ºå‘¨çº¿æ•°æ®
        
        Args:
            df: æ—¥çº¿æ•°æ®
            
        Returns:
            pd.DataFrame: å‘¨çº¿æ•°æ®
        """
        try:
            if df is None or df.empty:
                raise DataProcessError("è¾“å…¥æ•°æ®ä¸ºç©º")
            
            logger.info(f"å°†æ—¥çº¿æ•°æ®é‡é‡‡æ ·ä¸ºå‘¨çº¿ï¼ŒåŸå§‹æ•°æ® {len(df)} æ¡è®°å½•")
            
            # ç¡®ä¿ç´¢å¼•æ˜¯æ—¥æœŸç±»å‹
            if not isinstance(df.index, pd.DatetimeIndex):
                raise DataProcessError("æ•°æ®ç´¢å¼•å¿…é¡»æ˜¯æ—¥æœŸç±»å‹")
            
            # å®šä¹‰é‡é‡‡æ ·è§„åˆ™
            agg_rules = {
                'open': 'first',    # å¼€ç›˜ä»·å–ç¬¬ä¸€ä¸ª
                'high': 'max',      # æœ€é«˜ä»·å–æœ€å¤§å€¼
                'low': 'min',       # æœ€ä½ä»·å–æœ€å°å€¼
                'close': 'last',    # æ”¶ç›˜ä»·å–æœ€åä¸€ä¸ª
                'volume': 'sum'     # æˆäº¤é‡æ±‚å’Œ
            }
            
            # æ·»åŠ å…¶ä»–å¯èƒ½å­˜åœ¨çš„åˆ—
            if 'amount' in df.columns:
                agg_rules['amount'] = 'sum'
            if 'turnover_rate' in df.columns:
                agg_rules['turnover_rate'] = 'mean'
            
            # é‡é‡‡æ ·åˆ°å‘¨çº¿ï¼ˆå‘¨äº”ä¸ºä¸€å‘¨ç»“æŸï¼‰
            weekly_df = df.resample('W-FRI').agg(agg_rules)
            
            # åˆ é™¤å…¨ä¸ºNaNçš„è¡Œï¼ˆå¯èƒ½æ˜¯æ²¡æœ‰äº¤æ˜“çš„å‘¨ï¼‰
            weekly_df = weekly_df.dropna(how='all')
            
            # å¤„ç†éƒ¨åˆ†NaNå€¼
            # å¯¹äºä»·æ ¼æ•°æ®ï¼Œä½¿ç”¨å‰å‘å¡«å……åå†åå‘å¡«å……
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if col in weekly_df.columns:
                    weekly_df[col] = weekly_df[col].ffill().bfill()
            
            # å¯¹äºæˆäº¤é‡ï¼Œä½¿ç”¨0å¡«å……
            if 'volume' in weekly_df.columns:
                weekly_df['volume'] = weekly_df['volume'].fillna(0)
            
            # å¯¹äºæˆäº¤é¢ï¼Œä½¿ç”¨0å¡«å……
            if 'amount' in weekly_df.columns:
                weekly_df['amount'] = weekly_df['amount'].fillna(0)
            
            # ç¡®ä¿OHLCé€»è¾‘æ­£ç¡®
            weekly_df = self._fix_ohlc_logic(weekly_df)
            
            # æœ€ç»ˆæ£€æŸ¥ï¼Œåˆ é™¤ä»»ä½•ä»ç„¶æœ‰NaNçš„è¡Œ
            weekly_df = weekly_df.dropna()
            
            logger.info(f"é‡é‡‡æ ·å®Œæˆï¼Œå‘¨çº¿æ•°æ® {len(weekly_df)} æ¡è®°å½•")
            return weekly_df
            
        except Exception as e:
            raise DataProcessError(f"é‡é‡‡æ ·å¤±è´¥: {str(e)}") from e
    
    def _handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†ç¼ºå¤±å€¼"""
        try:
            # å¯¹äºä»·æ ¼æ•°æ®ï¼Œä½¿ç”¨å‰å‘å¡«å……
            price_columns = ['open', 'high', 'low', 'close']
            for col in price_columns:
                if col in df.columns:
                    # å…ˆå‰å‘å¡«å……ï¼Œå†åå‘å¡«å……
                    df[col] = df[col].ffill().bfill()
            
            # å¯¹äºæˆäº¤é‡ï¼Œä½¿ç”¨0å¡«å……ï¼ˆè¡¨ç¤ºæ— äº¤æ˜“ï¼‰
            if 'volume' in df.columns:
                df['volume'] = df['volume'].fillna(0)
            
            # å¯¹äºæˆäº¤é¢ï¼Œä½¿ç”¨0å¡«å……
            if 'amount' in df.columns:
                df['amount'] = df['amount'].fillna(0)
            
            # åˆ é™¤ä»ç„¶æœ‰ç¼ºå¤±å€¼çš„è¡Œ
            df = df.dropna()
            
            return df
            
        except Exception as e:
            raise DataProcessError(f"å¤„ç†ç¼ºå¤±å€¼å¤±è´¥: {str(e)}") from e
    
    def _handle_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†å¼‚å¸¸å€¼"""
        try:
            # å¤„ç†ä»·æ ¼å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨3å€æ ‡å‡†å·®è§„åˆ™ï¼‰
            price_columns = ['open', 'high', 'low', 'close']
            
            for col in price_columns:
                if col in df.columns and len(df) > 10:
                    # è®¡ç®—ä»·æ ¼å˜åŒ–ç‡
                    pct_change = df[col].pct_change().abs()
                    
                    # è¯†åˆ«å¼‚å¸¸å˜åŒ–ï¼ˆè¶…è¿‡3å€æ ‡å‡†å·®ï¼‰
                    mean_change = pct_change.mean()
                    std_change = pct_change.std()
                    threshold = mean_change + 3 * std_change
                    
                    outliers = pct_change > threshold
                    if outliers.any():
                        logger.warning(f"å‘ç° {outliers.sum()} ä¸ª {col} å¼‚å¸¸å€¼")
                        
                        # ç”¨å‰ä¸€ä¸ªæœ‰æ•ˆå€¼æ›¿æ¢å¼‚å¸¸å€¼
                        for idx in df.index[outliers]:
                            if idx != df.index[0]:  # ä¸æ˜¯ç¬¬ä¸€è¡Œ
                                prev_idx = df.index[df.index < idx][-1]
                                df.loc[idx, col] = df.loc[prev_idx, col]
            
            # å¤„ç†æˆäº¤é‡å¼‚å¸¸å€¼
            if 'volume' in df.columns and len(df) > 10:
                # æˆäº¤é‡ä¸èƒ½ä¸ºè´Ÿæ•°
                df.loc[df['volume'] < 0, 'volume'] = 0
                
                # å¤„ç†æç«¯å¤§çš„æˆäº¤é‡ï¼ˆè¶…è¿‡ä¸­ä½æ•°çš„100å€ï¼‰
                median_volume = df['volume'].median()
                if median_volume > 0:
                    extreme_volume = df['volume'] > median_volume * 100
                    if extreme_volume.any():
                        logger.warning(f"å‘ç° {extreme_volume.sum()} ä¸ªæˆäº¤é‡å¼‚å¸¸å€¼")
                        df.loc[extreme_volume, 'volume'] = median_volume
            
            return df
            
        except Exception as e:
            raise DataProcessError(f"å¤„ç†å¼‚å¸¸å€¼å¤±è´¥: {str(e)}") from e
    
    def _check_ohlc_logic(self, df: pd.DataFrame) -> int:
        """æ£€æŸ¥OHLCé€»è¾‘é”™è¯¯çš„è®°å½•æ•°"""
        try:
            if not all(col in df.columns for col in ['open', 'high', 'low', 'close']):
                return 0
            
            # æ£€æŸ¥ high >= max(open, close) å’Œ low <= min(open, close)
            invalid_high = df['high'] < df[['open', 'close']].max(axis=1)
            invalid_low = df['low'] > df[['open', 'close']].min(axis=1)
            
            return (invalid_high | invalid_low).sum()
            
        except Exception:
            return 0
    
    def _fix_ohlc_logic(self, df: pd.DataFrame) -> pd.DataFrame:
        """ä¿®æ­£OHLCé€»è¾‘é”™è¯¯"""
        try:
            if not all(col in df.columns for col in ['open', 'high', 'low', 'close']):
                return df
            
            # ä¿®æ­£æœ€é«˜ä»·ï¼šç¡®ä¿ high >= max(open, close)
            max_oc = df[['open', 'close']].max(axis=1)
            df.loc[df['high'] < max_oc, 'high'] = max_oc
            
            # ä¿®æ­£æœ€ä½ä»·ï¼šç¡®ä¿ low <= min(open, close)
            min_oc = df[['open', 'close']].min(axis=1)
            df.loc[df['low'] > min_oc, 'low'] = min_oc
            
            return df
            
        except Exception as e:
            logger.warning(f"ä¿®æ­£OHLCé€»è¾‘å¤±è´¥: {str(e)}")
            return df
    
    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ - å¸¦è¯¦ç»†è°ƒè¯•æ—¥å¿—
        
        Args:
            df: åŒ…å«OHLCVæ•°æ®çš„DataFrame
            
        Returns:
            pd.DataFrame: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„æ•°æ®
        """
        try:
            if df is None or df.empty:
                raise DataProcessError("è¾“å…¥æ•°æ®ä¸ºç©º")
            
            logger.info("=" * 60)
            logger.info("ğŸ” å¼€å§‹è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ - è¯¦ç»†è°ƒè¯•æ¨¡å¼")
            logger.info("=" * 60)
            
            # å¤åˆ¶æ•°æ®é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            result_df = df.copy()
            
            # è¾“å…¥æ•°æ®æ£€æŸ¥
            logger.info(f"ğŸ“Š è¾“å…¥æ•°æ®æ¦‚å†µ:")
            logger.info(f"   - æ•°æ®è¡Œæ•°: {len(result_df)}")
            logger.info(f"   - æ•°æ®åˆ—æ•°: {len(result_df.columns)}")
            logger.info(f"   - æ•°æ®èŒƒå›´: {result_df.index.min()} åˆ° {result_df.index.max()}")
            logger.info(f"   - æ”¶ç›˜ä»·èŒƒå›´: {result_df['close'].min():.4f} - {result_df['close'].max():.4f}")
            logger.info(f"   - æ”¶ç›˜ä»·NaNæ•°é‡: {result_df['close'].isna().sum()}")
            
            # è®¡ç®—RSI
            logger.info("\nğŸ”„ è®¡ç®—RSIæŒ‡æ ‡...")
            result_df['rsi'] = self._calculate_rsi_debug(result_df['close'])
            
            # è®¡ç®—EMA
            logger.info("\nğŸ”„ è®¡ç®—EMAæŒ‡æ ‡...")
            logger.info("   - è®¡ç®—EMA20...")
            result_df['ema_20'] = result_df['close'].ewm(span=20).mean()
            logger.info(f"   - EMA20 NaNæ•°é‡: {result_df['ema_20'].isna().sum()}")
            logger.info(f"   - EMA20 æœ€å5ä¸ªå€¼: {result_df['ema_20'].tail().values}")
            
            logger.info("   - è®¡ç®—EMA50...")
            result_df['ema_50'] = result_df['close'].ewm(span=50).mean()
            logger.info(f"   - EMA50 NaNæ•°é‡: {result_df['ema_50'].isna().sum()}")
            logger.info(f"   - EMA50 æœ€å5ä¸ªå€¼: {result_df['ema_50'].tail().values}")
            
            logger.info("   - è®¡ç®—EMA60...")
            result_df['ema_60'] = result_df['close'].ewm(span=60).mean()
            logger.info(f"   - EMA60 NaNæ•°é‡: {result_df['ema_60'].isna().sum()}")
            logger.info(f"   - EMA60 æœ€å5ä¸ªå€¼: {result_df['ema_60'].tail().values}")
            
            # è®¡ç®—MACD
            logger.info("\nğŸ”„ è®¡ç®—MACDæŒ‡æ ‡...")
            macd_data = self._calculate_macd_debug(result_df['close'])
            result_df['macd'] = macd_data['macd']
            result_df['macd_signal'] = macd_data['signal']
            result_df['macd_histogram'] = macd_data['histogram']
            
            # è®¡ç®—å¸ƒæ—å¸¦
            logger.info("\nğŸ”„ è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡...")
            bb_data = self._calculate_bollinger_bands_debug(result_df['close'])
            result_df['bb_upper'] = bb_data['upper']
            result_df['bb_middle'] = bb_data['middle']
            result_df['bb_lower'] = bb_data['lower']
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            logger.info("\nğŸ”„ è®¡ç®—ç§»åŠ¨å¹³å‡çº¿...")
            logger.info("   - è®¡ç®—MA5...")
            result_df['ma_5'] = result_df['close'].rolling(window=5).mean()
            logger.info(f"   - MA5 NaNæ•°é‡: {result_df['ma_5'].isna().sum()}")
            
            logger.info("   - è®¡ç®—MA10...")
            result_df['ma_10'] = result_df['close'].rolling(window=10).mean()
            logger.info(f"   - MA10 NaNæ•°é‡: {result_df['ma_10'].isna().sum()}")
            
            logger.info("   - è®¡ç®—MA20...")
            result_df['ma_20'] = result_df['close'].rolling(window=20).mean()
            logger.info(f"   - MA20 NaNæ•°é‡: {result_df['ma_20'].isna().sum()}")
            
            # è®¡ç®—æˆäº¤é‡æŒ‡æ ‡
            if 'volume' in result_df.columns:
                logger.info("\nğŸ”„ è®¡ç®—æˆäº¤é‡æŒ‡æ ‡...")
                logger.info(f"   - æˆäº¤é‡NaNæ•°é‡: {result_df['volume'].isna().sum()}")
                logger.info(f"   - æˆäº¤é‡èŒƒå›´: {result_df['volume'].min()} - {result_df['volume'].max()}")
                
                result_df['volume_ma'] = result_df['volume'].rolling(window=20).mean()
                logger.info(f"   - æˆäº¤é‡MA20 NaNæ•°é‡: {result_df['volume_ma'].isna().sum()}")
                
                # æ£€æŸ¥é™¤é›¶æƒ…å†µ
                zero_volume_ma = (result_df['volume_ma'] == 0).sum()
                logger.info(f"   - æˆäº¤é‡MA20ä¸º0çš„æ•°é‡: {zero_volume_ma}")
                
                result_df['volume_ratio'] = result_df['volume'] / result_df['volume_ma']
                logger.info(f"   - æˆäº¤é‡æ¯”ç‡ NaNæ•°é‡: {result_df['volume_ratio'].isna().sum()}")
                logger.info(f"   - æˆäº¤é‡æ¯”ç‡ æ— ç©·å¤§æ•°é‡: {np.isinf(result_df['volume_ratio']).sum()}")
            
            # æœ€ç»ˆç»Ÿè®¡
            logger.info("\nğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆç»Ÿè®¡:")
            logger.info("-" * 40)
            for col in result_df.columns:
                if col not in ['open', 'high', 'low', 'close', 'volume']:
                    nan_count = result_df[col].isna().sum()
                    inf_count = np.isinf(result_df[col]).sum() if result_df[col].dtype in ['float64', 'float32'] else 0
                    logger.info(f"   {col:15}: NaN={nan_count:3d}, Inf={inf_count:3d}")
            
            logger.info("=" * 60)
            
            return result_df
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            raise DataProcessError(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {str(e)}") from e
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡ - ä½¿ç”¨TA-Lib"""
        try:
            from indicators.momentum import calculate_rsi
            return calculate_rsi(prices, period)
        except Exception as e:
            raise DataProcessError(f"RSIè®¡ç®—å¤±è´¥: {str(e)}") from e
    
    def _calculate_rsi_debug(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡ - ä½¿ç”¨TA-Lib"""
        try:
            logger.info(f"   - RSIè®¡ç®—è¾“å…¥: ä»·æ ¼åºåˆ—é•¿åº¦={len(prices)}, å‘¨æœŸ={period}")
            logger.info(f"   - ä»·æ ¼åºåˆ—NaNæ•°é‡: {prices.isna().sum()}")
            
            from indicators.momentum import calculate_rsi
            rsi = calculate_rsi(prices, period)
            logger.info(f"   - ä½¿ç”¨TA-Libè®¡ç®—RSIæˆåŠŸ")
            logger.info(f"   - RSI NaNæ•°é‡: {rsi.isna().sum()}")
            logger.info(f"   - RSI æœ€å5ä¸ªå€¼: {rsi.tail().values}")
            return rsi
            
        except Exception as e:
            logger.error(f"   - RSIè®¡ç®—å¤±è´¥: {str(e)}")
            raise DataProcessError(f"RSIè®¡ç®—å¤±è´¥: {str(e)}") from e
    
    def _calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> dict:
        """è®¡ç®—MACDæŒ‡æ ‡"""
        try:
            ema_fast = prices.ewm(span=fast).mean()
            ema_slow = prices.ewm(span=slow).mean()
            macd = ema_fast - ema_slow
            macd_signal = macd.ewm(span=signal).mean()
            macd_histogram = macd - macd_signal
            
            return {
                'macd': macd,
                'signal': macd_signal,
                'histogram': macd_histogram
            }
        except Exception:
            return {
                'macd': pd.Series(index=prices.index, dtype=float),
                'signal': pd.Series(index=prices.index, dtype=float),
                'histogram': pd.Series(index=prices.index, dtype=float)
            }
    
    def _calculate_macd_debug(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> dict:
        """è®¡ç®—MACDæŒ‡æ ‡ - ä½¿ç”¨TA-Lib"""
        try:
            logger.info(f"   - MACDè®¡ç®—è¾“å…¥: ä»·æ ¼åºåˆ—é•¿åº¦={len(prices)}, å¿«çº¿={fast}, æ…¢çº¿={slow}, ä¿¡å·çº¿={signal}")
            
            from indicators.momentum import calculate_macd
            macd_result = calculate_macd(prices, fast, slow, signal)
            
            logger.info(f"   - ä½¿ç”¨TA-Libè®¡ç®—MACDæˆåŠŸ")
            logger.info(f"   - MACDçº¿ NaNæ•°é‡: {macd_result['dif'].isna().sum()}")
            logger.info(f"   - MACDä¿¡å·çº¿ NaNæ•°é‡: {macd_result['dea'].isna().sum()}")
            logger.info(f"   - MACDæŸ±çŠ¶å›¾ NaNæ•°é‡: {macd_result['hist'].isna().sum()}")
            logger.info(f"   - MACDçº¿èŒƒå›´: {macd_result['dif'].min():.6f} - {macd_result['dif'].max():.6f}")
            logger.info(f"   - MACDæŸ±çŠ¶å›¾èŒƒå›´: {macd_result['hist'].min():.6f} - {macd_result['hist'].max():.6f}")
            
            return {
                'macd': macd_result['dif'],
                'signal': macd_result['dea'],
                'histogram': macd_result['hist']
            }
            
        except Exception as e:
            logger.error(f"   - MACDè®¡ç®—å¤±è´¥: {str(e)}")
            raise DataProcessError(f"MACDè®¡ç®—å¤±è´¥: {str(e)}") from e
    
    def _calculate_bollinger_bands(self, prices: pd.Series, period: int = 20, std_dev: float = 2) -> dict:
        """è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡ - ä½¿ç”¨TA-Lib"""
        try:
            import talib
            
            # ä½¿ç”¨TA-Libè®¡ç®—å¸ƒæ—å¸¦
            upper_values, middle_values, lower_values = talib.BBANDS(
                prices.values,
                timeperiod=period,
                nbdevup=std_dev,
                nbdevdn=std_dev,
                matype=0  # ç®€å•ç§»åŠ¨å¹³å‡
            )
            
            return {
                'upper': pd.Series(upper_values, index=prices.index),
                'middle': pd.Series(middle_values, index=prices.index),
                'lower': pd.Series(lower_values, index=prices.index)
            }
        except Exception as e:
            raise DataProcessError(f"å¸ƒæ—å¸¦è®¡ç®—å¤±è´¥: {str(e)}") from e
    
    def _calculate_bollinger_bands_debug(self, prices: pd.Series, period: int = 20, std_dev: float = 2) -> dict:
        """è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡ - ä½¿ç”¨TA-Lib"""
        try:
            logger.info(f"   - å¸ƒæ—å¸¦è®¡ç®—è¾“å…¥: ä»·æ ¼åºåˆ—é•¿åº¦={len(prices)}, å‘¨æœŸ={period}, æ ‡å‡†å·®å€æ•°={std_dev}")
            
            import talib
            
            # ä½¿ç”¨TA-Libè®¡ç®—å¸ƒæ—å¸¦
            upper_values, middle_values, lower_values = talib.BBANDS(
                prices.values,
                timeperiod=period,
                nbdevup=std_dev,
                nbdevdn=std_dev,
                matype=0  # ç®€å•ç§»åŠ¨å¹³å‡
            )
            
            upper = pd.Series(upper_values, index=prices.index)
            middle = pd.Series(middle_values, index=prices.index)
            lower = pd.Series(lower_values, index=prices.index)
            
            logger.info(f"   - ä½¿ç”¨TA-Libè®¡ç®—å¸ƒæ—å¸¦æˆåŠŸ")
            logger.info(f"   - ä¸Šè½¨ NaNæ•°é‡: {upper.isna().sum()}")
            logger.info(f"   - ä¸­è½¨ NaNæ•°é‡: {middle.isna().sum()}")
            logger.info(f"   - ä¸‹è½¨ NaNæ•°é‡: {lower.isna().sum()}")
            logger.info(f"   - ä¸Šè½¨èŒƒå›´: {upper.min():.6f} - {upper.max():.6f}")
            logger.info(f"   - ä¸‹è½¨èŒƒå›´: {lower.min():.6f} - {lower.max():.6f}")
            
            return {
                'upper': upper,
                'middle': middle,
                'lower': lower
            }
            
        except Exception as e:
            logger.error(f"   - å¸ƒæ—å¸¦è®¡ç®—å¤±è´¥: {str(e)}")
            raise DataProcessError(f"å¸ƒæ—å¸¦è®¡ç®—å¤±è´¥: {str(e)}") from e

    def get_data_summary(self, df: pd.DataFrame) -> dict:
        """
        è·å–æ•°æ®æ‘˜è¦ä¿¡æ¯
        
        Args:
            df: æ•°æ®DataFrame
            
        Returns:
            dict: æ•°æ®æ‘˜è¦
        """
        try:
            if df is None or df.empty:
                return {"error": "æ•°æ®ä¸ºç©º"}
            
            summary = {
                "è®°å½•æ•°": len(df),
                "å¼€å§‹æ—¥æœŸ": df.index.min().strftime('%Y-%m-%d') if not df.empty else None,
                "ç»“æŸæ—¥æœŸ": df.index.max().strftime('%Y-%m-%d') if not df.empty else None,
                "åˆ—æ•°": len(df.columns),
                "åˆ—å": list(df.columns),
                "ç¼ºå¤±å€¼": df.isnull().sum().to_dict(),
                "æ•°æ®ç±»å‹": df.dtypes.to_dict()
            }
            
            # æ·»åŠ ä»·æ ¼ç»Ÿè®¡ä¿¡æ¯
            if 'close' in df.columns:
                summary["æ”¶ç›˜ä»·ç»Ÿè®¡"] = {
                    "æœ€å°å€¼": float(df['close'].min()),
                    "æœ€å¤§å€¼": float(df['close'].max()),
                    "å¹³å‡å€¼": float(df['close'].mean()),
                    "æ ‡å‡†å·®": float(df['close'].std())
                }
            
            return summary
            
        except Exception as e:
            return {"error": f"ç”Ÿæˆæ•°æ®æ‘˜è¦å¤±è´¥: {str(e)}"}

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')
    test_data = pd.DataFrame({
        'open': np.random.uniform(10, 20, len(dates)),
        'high': np.random.uniform(15, 25, len(dates)),
        'low': np.random.uniform(5, 15, len(dates)),
        'close': np.random.uniform(10, 20, len(dates)),
        'volume': np.random.randint(1000, 10000, len(dates))
    }, index=dates)
    
    # æ·»åŠ ä¸€äº›å¼‚å¸¸å€¼è¿›è¡Œæµ‹è¯•
    test_data.loc[test_data.index[10], 'high'] = test_data.loc[test_data.index[10], 'low'] - 1  # OHLCé€»è¾‘é”™è¯¯
    test_data.loc[test_data.index[20:25], 'close'] = np.nan  # ç¼ºå¤±å€¼
    
    processor = DataProcessor()
    
    # æµ‹è¯•æ•°æ®éªŒè¯
    is_valid, issues = processor.validate_data(test_data)
    print(f"æ•°æ®éªŒè¯ç»“æœ: {is_valid}")
    if issues:
        print(f"å‘ç°é—®é¢˜: {issues}")
    
    # æµ‹è¯•æ•°æ®æ¸…æ´—
    cleaned_data = processor.clean_data(test_data)
    print(f"æ¸…æ´—å‰: {len(test_data)} æ¡è®°å½•")
    print(f"æ¸…æ´—å: {len(cleaned_data)} æ¡è®°å½•")
    
    # æµ‹è¯•é‡é‡‡æ ·
    weekly_data = processor.resample_to_weekly(cleaned_data)
    print(f"å‘¨çº¿æ•°æ®: {len(weekly_data)} æ¡è®°å½•")
    
    # æµ‹è¯•æ•°æ®æ‘˜è¦
    summary = processor.get_data_summary(weekly_data)
    print(f"æ•°æ®æ‘˜è¦: {summary}")