"""
æ•°æ®è·å–å™¨æ¨¡å—
æ”¯æŒä»ä¸åŒæ•°æ®æºè·å–è‚¡ç¥¨æ•°æ®
"""

import akshare as ak
import pandas as pd
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from abc import ABC, abstractmethod

from .exceptions import DataFetchError

logger = logging.getLogger(__name__)

class DataFetcher(ABC):
    """æ•°æ®è·å–å™¨åŸºç±»"""
    
    @abstractmethod
    def get_stock_data(self, code: str, start_date: str, end_date: str = None, 
                      period: str = 'weekly') -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨å†å²æ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç  (å¦‚ '601088')
            start_date: å¼€å§‹æ—¥æœŸ ('YYYY-MM-DD')
            end_date: ç»“æŸæ—¥æœŸ ('YYYY-MM-DD', Noneè¡¨ç¤ºå½“å‰æ—¥æœŸ)
            period: æ•°æ®å‘¨æœŸ ('daily', 'weekly', 'monthly')
            
        Returns:
            pd.DataFrame: æ ‡å‡†åŒ–çš„è‚¡ç¥¨æ•°æ®
            
        Raises:
            DataFetchError: æ•°æ®è·å–å¤±è´¥
        """
        pass
    
    def get_multiple_stocks_data(self, codes: List[str], start_date: str, 
                               end_date: str = None, period: str = 'weekly') -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®
        
        Args:
            codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            period: æ•°æ®å‘¨æœŸ
            
        Returns:
            Dict[str, pd.DataFrame]: è‚¡ç¥¨ä»£ç åˆ°æ•°æ®çš„æ˜ å°„
        """
        result = {}
        failed_codes = []
        
        for code in codes:
            try:
                logger.info(f"è·å–è‚¡ç¥¨ {code} çš„æ•°æ®...")
                data = self.get_stock_data(code, start_date, end_date, period)
                result[code] = data
                logger.info(f"æˆåŠŸè·å–è‚¡ç¥¨ {code} çš„æ•°æ®ï¼Œå…± {len(data)} æ¡è®°å½•")
            except Exception as e:
                logger.error(f"è·å–è‚¡ç¥¨ {code} æ•°æ®å¤±è´¥: {str(e)}")
                failed_codes.append(code)
        
        if failed_codes:
            logger.warning(f"ä»¥ä¸‹è‚¡ç¥¨æ•°æ®è·å–å¤±è´¥: {failed_codes}")
        
        return result

class AkshareDataFetcher(DataFetcher):
    """Akshareæ•°æ®è·å–å™¨å®ç°"""
    
    def __init__(self):
        """åˆå§‹åŒ–Akshareæ•°æ®è·å–å™¨"""
        self.source_name = "akshare"
        self.last_request_time = None  # è®°å½•ä¸Šæ¬¡è¯·æ±‚æ—¶é—´
        self.min_request_interval = 1.0  # æœ€å°è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
        logger.info("åˆå§‹åŒ–Akshareæ•°æ®è·å–å™¨")
    
    def get_stock_data(self, code: str, start_date: str, end_date: str = None, 
                      period: str = 'weekly') -> pd.DataFrame:
        """
        ä»Akshareè·å–è‚¡ç¥¨å†å²æ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç  (å¦‚ '601088')
            start_date: å¼€å§‹æ—¥æœŸ ('YYYY-MM-DD')
            end_date: ç»“æŸæ—¥æœŸ ('YYYY-MM-DD', Noneè¡¨ç¤ºå½“å‰æ—¥æœŸ)
            period: æ•°æ®å‘¨æœŸ ('daily', 'weekly', 'monthly')
            
        Returns:
            pd.DataFrame: æ ‡å‡†åŒ–çš„è‚¡ç¥¨æ•°æ®
            
        Raises:
            DataFetchError: æ•°æ®è·å–å¤±è´¥
        """
        try:
            # å‚æ•°éªŒè¯
            if not self._validate_stock_code(code):
                raise DataFetchError(f"æ— æ•ˆçš„è‚¡ç¥¨ä»£ç : {code}")
            
            if not self._validate_date_format(start_date):
                raise DataFetchError(f"æ— æ•ˆçš„å¼€å§‹æ—¥æœŸæ ¼å¼: {start_date}")
            
            if end_date and not self._validate_date_format(end_date):
                raise DataFetchError(f"æ— æ•ˆçš„ç»“æŸæ—¥æœŸæ ¼å¼: {end_date}")
            
            # è®¾ç½®é»˜è®¤ç»“æŸæ—¥æœŸ
            if end_date is None:
                end_date = datetime.now().strftime('%Y%m%d')
            else:
                # æ­£ç¡®å¤„ç†æ—¥æœŸæ ¼å¼ï¼Œæ”¯æŒç¼ºå°‘å‰å¯¼é›¶çš„æƒ…å†µ
                try:
                    parsed_end_date = datetime.strptime(end_date, '%Y-%m-%d')
                    end_date = parsed_end_date.strftime('%Y%m%d')
                except ValueError:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•å¤„ç†ç¼ºå°‘å‰å¯¼é›¶çš„æƒ…å†µ
                    parts = end_date.split('-')
                    if len(parts) == 3:
                        year, month, day = parts
                        month = month.zfill(2)
                        day = day.zfill(2)
                        fixed_date = f'{year}-{month}-{day}'
                        parsed_end_date = datetime.strptime(fixed_date, '%Y-%m-%d')
                        end_date = parsed_end_date.strftime('%Y%m%d')
                    else:
                        raise DataFetchError(f"æ— æ³•è§£æç»“æŸæ—¥æœŸæ ¼å¼: {end_date}")
            
            # æ­£ç¡®å¤„ç†å¼€å§‹æ—¥æœŸæ ¼å¼
            try:
                parsed_start_date = datetime.strptime(start_date, '%Y-%m-%d')
                start_date = parsed_start_date.strftime('%Y%m%d')
            except ValueError:
                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•å¤„ç†ç¼ºå°‘å‰å¯¼é›¶çš„æƒ…å†µ
                parts = start_date.split('-')
                if len(parts) == 3:
                    year, month, day = parts
                    month = month.zfill(2)
                    day = day.zfill(2)
                    fixed_date = f'{year}-{month}-{day}'
                    parsed_start_date = datetime.strptime(fixed_date, '%Y-%m-%d')
                    start_date = parsed_start_date.strftime('%Y%m%d')
                else:
                    raise DataFetchError(f"æ— æ³•è§£æå¼€å§‹æ—¥æœŸæ ¼å¼: {start_date}")
            
            # æ˜ å°„å‘¨æœŸå‚æ•°
            period_map = {
                'daily': 'daily',
                'weekly': 'weekly', 
                'monthly': 'monthly'
            }
            
            if period not in period_map:
                raise DataFetchError(f"ä¸æ”¯æŒçš„æ•°æ®å‘¨æœŸ: {period}")
            
            ak_period = period_map[period]
            
            logger.debug(f"ä»Akshareè·å–æ•°æ®: {code}, {start_date}-{end_date}, {ak_period}")
            
            # è°ƒç”¨akshareæ¥å£è·å–æ•°æ®ï¼Œå¢åŠ é‡è¯•æœºåˆ¶
            max_retries = 5  # å¢åŠ é‡è¯•æ¬¡æ•°
            df = None
            
            for attempt in range(max_retries):
                try:
                    import time
                    
                    # æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¿å…è§¦å‘åçˆ¬è™«
                    if self.last_request_time is not None:
                        elapsed = time.time() - self.last_request_time
                        if elapsed < self.min_request_interval:
                            sleep_time = self.min_request_interval - elapsed
                            logger.debug(f"è¯·æ±‚é—´éš”æ§åˆ¶ï¼šç­‰å¾… {sleep_time:.2f} ç§’")
                            time.sleep(sleep_time)
                    
                    # é‡è¯•æ—¶å¢åŠ é¢å¤–å»¶è¿Ÿ
                    if attempt > 0:
                        time.sleep(2 + attempt)  # é€’å¢å»¶è¿Ÿ
                    
                    # æ›´æ–°è¯·æ±‚æ—¶é—´
                    self.last_request_time = time.time()
                    
                    logger.debug(f"å°è¯•è·å–è‚¡ç¥¨ {code} æ•°æ®ï¼Œç¬¬ {attempt + 1} æ¬¡")
                    
                    # å°è¯•ä¸åŒçš„è·å–æ–¹å¼
                    if attempt < 3:
                        # å‰3æ¬¡ä½¿ç”¨æ ‡å‡†æ–¹å¼
                        df = ak.stock_zh_a_hist(
                            symbol=code,
                            period=ak_period,
                            start_date=start_date,
                            end_date=end_date,
                            adjust=""  # ä¸å¤æƒæ•°æ®
                        )
                    else:
                        # åç»­å°è¯•ä½¿ç”¨ä¸åŒå‚æ•°
                        df = ak.stock_zh_a_hist(
                            symbol=code,
                            period="daily",  # æ”¹ç”¨æ—¥çº¿æ•°æ®
                            start_date=start_date,
                            end_date=end_date,
                            adjust=""  # ä¸å¤æƒæ•°æ®
                        )
                    
                    if df is not None and not df.empty:
                        logger.debug(f"æˆåŠŸè·å–è‚¡ç¥¨ {code} æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
                        break
                    else:
                        logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•è·å–è‚¡ç¥¨ {code} æ•°æ®ä¸ºç©º")
                        
                except Exception as e:
                    logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•è·å–è‚¡ç¥¨ {code} æ•°æ®å¤±è´¥: {str(e)}")
                    if attempt < max_retries - 1:
                        time.sleep(3 + attempt)  # é€’å¢ç­‰å¾…æ—¶é—´
                    else:
                        # æœ€åä¸€æ¬¡å°è¯•ï¼Œè®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                        logger.error(f"æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œè‚¡ç¥¨ {code} å¯èƒ½æš‚æ—¶æ— æ³•è·å–æ•°æ®")
            
            if df is None or df.empty:
                raise DataFetchError(f"æœªè·å–åˆ°è‚¡ç¥¨ {code} çš„æ•°æ®")
            
            # æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
            df = self._standardize_data_format(df)
            
            logger.debug(f"æˆåŠŸè·å–è‚¡ç¥¨ {code} æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
            return df
            
        except Exception as e:
            error_msg = f"è·å–è‚¡ç¥¨ {code} æ•°æ®å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            raise DataFetchError(error_msg) from e
    
    def _standardize_data_format(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
        
        Args:
            df: åŸå§‹akshareæ•°æ®
            
        Returns:
            pd.DataFrame: æ ‡å‡†åŒ–åçš„æ•°æ®
        """
        try:
            # é‡å‘½ååˆ—åä¸ºè‹±æ–‡æ ‡å‡†æ ¼å¼
            column_mapping = {
                'æ—¥æœŸ': 'date',
                'å¼€ç›˜': 'open',
                'æ”¶ç›˜': 'close', 
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount',
                'æŒ¯å¹…': 'amplitude',
                'æ¶¨è·Œå¹…': 'pct_change',
                'æ¶¨è·Œé¢': 'change',
                'æ¢æ‰‹ç‡': 'turnover_rate'
            }
            
            # é‡å‘½åå­˜åœ¨çš„åˆ—
            existing_columns = {k: v for k, v in column_mapping.items() if k in df.columns}
            df = df.rename(columns=existing_columns)
            
            # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
            required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                raise DataFetchError(f"ç¼ºå°‘å¿…è¦çš„æ•°æ®åˆ—: {missing_columns}")
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            df['date'] = pd.to_datetime(df['date'])
            
            # è®¾ç½®æ—¥æœŸä¸ºç´¢å¼•
            df = df.set_index('date')
            
            # ç¡®ä¿æ•°å€¼åˆ—ä¸ºfloatç±»å‹
            numeric_columns = ['open', 'high', 'low', 'close', 'volume']
            if 'amount' in df.columns:
                numeric_columns.append('amount')
            if 'turnover_rate' in df.columns:
                numeric_columns.append('turnover_rate')
            
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # æŒ‰æ—¥æœŸæ’åº
            df = df.sort_index()
            
            # é€‰æ‹©éœ€è¦çš„åˆ—
            output_columns = ['open', 'high', 'low', 'close', 'volume']
            if 'amount' in df.columns:
                output_columns.append('amount')
            if 'turnover_rate' in df.columns:
                output_columns.append('turnover_rate')
            
            df = df[output_columns]
            
            return df
            
        except Exception as e:
            raise DataFetchError(f"æ•°æ®æ ¼å¼æ ‡å‡†åŒ–å¤±è´¥: {str(e)}") from e
    
    def _validate_stock_code(self, code: str) -> bool:
        """
        éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            bool: æ˜¯å¦æœ‰æ•ˆ
        """
        if not code or not isinstance(code, str):
            return False
        
        # ç®€å•éªŒè¯ï¼š6ä½æ•°å­—
        return len(code) == 6 and code.isdigit()
    
    def _validate_date_format(self, date_str: str) -> bool:
        """
        éªŒè¯æ—¥æœŸæ ¼å¼
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            
        Returns:
            bool: æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            datetime.strptime(date_str, '%Y-%m-%d')
            return True
        except ValueError:
            return False
    
    def get_latest_trading_date(self) -> str:
        """
        è·å–æœ€æ–°äº¤æ˜“æ—¥æœŸ
        
        Returns:
            str: æœ€æ–°äº¤æ˜“æ—¥æœŸ ('YYYY-MM-DD')
        """
        try:
            # è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥å†
            today = datetime.now()
            
            # ç®€å•å®ç°ï¼šå¦‚æœæ˜¯å‘¨æœ«ï¼Œå›é€€åˆ°å‘¨äº”
            weekday = today.weekday()
            if weekday == 5:  # å‘¨å…­
                latest_date = today - timedelta(days=1)
            elif weekday == 6:  # å‘¨æ—¥
                latest_date = today - timedelta(days=2)
            else:
                latest_date = today
            
            return latest_date.strftime('%Y-%m-%d')
            
        except Exception as e:
            logger.error(f"è·å–æœ€æ–°äº¤æ˜“æ—¥æœŸå¤±è´¥: {str(e)}")
            return datetime.now().strftime('%Y-%m-%d')
    
    def test_connection(self) -> bool:
        """
        æµ‹è¯•æ•°æ®æºè¿æ¥
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æ­£å¸¸
        """
        try:
            # å°è¯•è·å–ä¸€åªè‚¡ç¥¨çš„å°‘é‡æ•°æ®æ¥æµ‹è¯•è¿æ¥
            test_code = "000001"  # å¹³å®‰é“¶è¡Œ
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=7)).strftime('%Y%m%d')
            
            df = ak.stock_zh_a_hist(
                symbol=test_code,
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust="qfq"
            )
            
            return df is not None and not df.empty
            
        except Exception as e:
            logger.error(f"æµ‹è¯•Akshareè¿æ¥å¤±è´¥: {str(e)}")
            return False
    
    def get_dividend_data(self, code: str, start_date: str, end_date: str = None, 
                         use_cache: bool = True) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨åˆ†çº¢é…è‚¡æ•°æ®ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
        
        Args:
            code: è‚¡ç¥¨ä»£ç  (å¦‚ '601088')
            start_date: å¼€å§‹æ—¥æœŸ ('YYYY-MM-DD')
            end_date: ç»“æŸæ—¥æœŸ ('YYYY-MM-DD', Noneè¡¨ç¤ºå½“å‰æ—¥æœŸ)
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            pd.DataFrame: åˆ†çº¢é…è‚¡æ•°æ®
            
        Raises:
            DataFetchError: æ•°æ®è·å–å¤±è´¥
        """
        try:
            # å¯¼å…¥æ•°æ®å­˜å‚¨æ¨¡å—
            from .data_storage import DataStorage
            storage = DataStorage()
            
            # å¦‚æœå¯ç”¨ç¼“å­˜ï¼Œå…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦çš„æ—¥æœŸèŒƒå›´å·²è¢«ç¼“å­˜è¦†ç›–
            if use_cache:
                # æ£€æŸ¥æŒ‡å®šæ—¥æœŸèŒƒå›´æ˜¯å¦å·²è¢«ç¼“å­˜å®Œå…¨è¦†ç›–
                if storage.is_dividend_date_range_cached(code, start_date or '1990-01-01', 
                                                       end_date or datetime.now().strftime('%Y-%m-%d')):
                    cached_data = storage.load_dividend_data(code)
                    if cached_data is not None:
                        logger.info(f"ğŸ“¦ ä½¿ç”¨åˆ†çº¢é…è‚¡ç¼“å­˜æ•°æ®: {code}")
                        
                        # æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤ç¼“å­˜æ•°æ®
                        filtered_data = cached_data.copy()
                        if start_date:
                            start_dt = pd.to_datetime(start_date)
                            filtered_data = filtered_data[filtered_data.index >= start_dt]
                        
                        if end_date:
                            end_dt = pd.to_datetime(end_date)
                            filtered_data = filtered_data[filtered_data.index <= end_dt]
                        
                        logger.info(f"âœ… ç¼“å­˜åˆ†çº¢é…è‚¡æ•°æ®è¿‡æ»¤å: {code}, {len(filtered_data)} æ¡è®°å½•")
                        return filtered_data
                else:
                    # ç¼“å­˜èŒƒå›´ä¸è¶³ï¼Œéœ€è¦ä»ç½‘ç»œè·å–
                    cache_coverage = storage.get_dividend_cache_coverage(code)
                    if cache_coverage:
                        logger.info(f"ğŸ“Š {code} ç¼“å­˜èŒƒå›´ä¸è¶³ï¼Œéœ€è¦ç½‘ç»œè·å–")
                        logger.info(f"  ç¼“å­˜èŒƒå›´: {cache_coverage['start_date']} åˆ° {cache_coverage['end_date']}")
                        logger.info(f"  éœ€è¦èŒƒå›´: {start_date or '1990-01-01'} åˆ° {end_date or datetime.now().strftime('%Y-%m-%d')}")
                    else:
                        logger.info(f"ğŸ“Š {code} æ— åˆ†çº¢é…è‚¡ç¼“å­˜ï¼Œéœ€è¦ç½‘ç»œè·å–")
            
            # ç¼“å­˜ä¸å­˜åœ¨æˆ–è¿‡æœŸï¼Œä»ç½‘ç»œè·å–
            logger.info(f"ğŸŒ ä»ç½‘ç»œè·å–è‚¡ç¥¨ {code} çš„åˆ†çº¢é…è‚¡æ•°æ®...")
            
            # æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¿å…è§¦å‘åçˆ¬è™«
            import time
            if self.last_request_time is not None:
                elapsed = time.time() - self.last_request_time
                if elapsed < self.min_request_interval:
                    sleep_time = self.min_request_interval - elapsed
                    logger.debug(f"è¯·æ±‚é—´éš”æ§åˆ¶ï¼šç­‰å¾… {sleep_time:.2f} ç§’")
                    time.sleep(sleep_time)
            
            # æ›´æ–°è¯·æ±‚æ—¶é—´
            self.last_request_time = time.time()
            
            # ä½¿ç”¨å¯ç”¨çš„akshare API
            dividend_data = ak.stock_history_dividend_detail(symbol=code)
            
            if dividend_data is None or dividend_data.empty:
                logger.warning(f"æœªè·å–åˆ°è‚¡ç¥¨ {code} çš„åˆ†çº¢é…è‚¡æ•°æ®")
                # å³ä½¿æ˜¯ç©ºæ•°æ®ä¹Ÿè¦ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚
                if use_cache:
                    empty_df = pd.DataFrame()
                    storage.save_dividend_data(empty_df, code)
                return pd.DataFrame()
            
            logger.info(f"åŸå§‹åˆ†çº¢æ•°æ®åˆ—å: {list(dividend_data.columns)}")
            logger.info(f"åŸå§‹æ•°æ®æ ·ä¾‹:\n{dividend_data.head(2)}")
            
            # æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–
            processed_data = self._process_dividend_data(dividend_data)
            
            # ä¿å­˜åˆ°ç¼“å­˜
            if use_cache and not processed_data.empty:
                storage.save_dividend_data(processed_data, code)
                logger.info(f"ğŸ’¾ åˆ†çº¢é…è‚¡æ•°æ®å·²ç¼“å­˜: {code}")
            
            # æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤
            filtered_data = processed_data.copy()
            if start_date:
                start_dt = pd.to_datetime(start_date)
                filtered_data = filtered_data[filtered_data.index >= start_dt]
            
            if end_date:
                end_dt = pd.to_datetime(end_date)
                filtered_data = filtered_data[filtered_data.index <= end_dt]
            
            logger.info(f"æˆåŠŸè·å–è‚¡ç¥¨ {code} çš„åˆ†çº¢é…è‚¡æ•°æ®ï¼Œå…± {len(filtered_data)} æ¡è®°å½•")
            return filtered_data
            
        except Exception as e:
            error_msg = f"è·å–è‚¡ç¥¨ {code} åˆ†çº¢é…è‚¡æ•°æ®å¤±è´¥: {str(e)}"
            logger.warning(error_msg)
            # è¿”å›ç©ºæ•°æ®è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ï¼Œä»¥å…å½±å“æ•´ä¸ªå›æµ‹
            return pd.DataFrame()
    
    def align_dividend_with_weekly_data(self, weekly_data: pd.DataFrame, 
                                      dividend_data: pd.DataFrame) -> pd.DataFrame:
        """
        å°†åˆ†çº¢é…è‚¡æ•°æ®ä¸å‘¨çº¿æ•°æ®å¯¹é½
        
        Args:
            weekly_data: å‘¨çº¿æ•°æ®
            dividend_data: åˆ†çº¢é…è‚¡æ•°æ®
            
        Returns:
            pd.DataFrame: å¯¹é½åçš„å‘¨çº¿æ•°æ®ï¼ŒåŒ…å«åˆ†çº¢é…è‚¡ä¿¡æ¯
        """
        try:
            if dividend_data.empty:
                # å¦‚æœæ²¡æœ‰åˆ†çº¢é…è‚¡æ•°æ®ï¼Œæ·»åŠ ç©ºåˆ—
                weekly_data['dividend_amount'] = 0.0
                weekly_data['allotment_ratio'] = 0.0
                weekly_data['allotment_price'] = 0.0
                weekly_data['bonus_ratio'] = 0.0
                weekly_data['transfer_ratio'] = 0.0
                return weekly_data
            
            # ç¡®ä¿ç´¢å¼•æ˜¯æ—¥æœŸç±»å‹
            weekly_data.index = pd.to_datetime(weekly_data.index)
            
            # åˆå§‹åŒ–åˆ†çº¢é…è‚¡åˆ—
            weekly_data['dividend_amount'] = 0.0
            weekly_data['allotment_ratio'] = 0.0
            weekly_data['allotment_price'] = 0.0
            weekly_data['bonus_ratio'] = 0.0
            weekly_data['transfer_ratio'] = 0.0
            
            # å°†åˆ†çº¢é…è‚¡æ—¥æœŸæ˜ å°„åˆ°å¯¹åº”çš„å‘¨çº¿æ—¥æœŸ
            for ex_date, dividend_row in dividend_data.iterrows():
                # ex_date å·²ç»æ˜¯ç´¢å¼•ï¼Œä¸éœ€è¦ä» dividend_row ä¸­è·å–
                
                # æ‰¾åˆ°æœ€æ¥è¿‘çš„å‘¨çº¿æ—¥æœŸï¼ˆé€šå¸¸æ˜¯å½“å‘¨æˆ–ä¸‹å‘¨çš„å‘¨äº”ï¼‰
                # æ‰¾åˆ°é™¤æƒé™¤æ¯æ—¥æ‰€åœ¨å‘¨çš„å‘¨äº”ï¼Œå¦‚æœé™¤æƒæ—¥åœ¨å‘¨äº”ä¹‹åï¼Œåˆ™æ˜ å°„åˆ°ä¸‹å‘¨äº”
                weekday = ex_date.weekday()  # 0=Monday, 4=Friday
                
                if weekday <= 4:  # å‘¨ä¸€åˆ°å‘¨äº”
                    # æ˜ å°„åˆ°å½“å‘¨å‘¨äº”
                    days_to_friday = 4 - weekday
                    target_friday = ex_date + pd.Timedelta(days=days_to_friday)
                else:  # å‘¨å…­å‘¨æ—¥
                    # æ˜ å°„åˆ°ä¸‹å‘¨å‘¨äº”
                    days_to_next_friday = 4 + (7 - weekday)
                    target_friday = ex_date + pd.Timedelta(days=days_to_next_friday)
                
                # æ‰¾åˆ°æœ€æ¥è¿‘çš„å‘¨çº¿æ•°æ®æ—¥æœŸ
                closest_date = None
                min_diff = float('inf')
                
                for week_date in weekly_data.index:
                    diff = abs((week_date - target_friday).days)
                    if diff < min_diff:
                        min_diff = diff
                        closest_date = week_date
                
                # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„æ—¥æœŸï¼Œæ›´æ–°åˆ†çº¢é…è‚¡ä¿¡æ¯
                if closest_date is not None and min_diff <= 7:  # å…è®¸7å¤©å†…çš„è¯¯å·®
                    weekly_data.loc[closest_date, 'dividend_amount'] = dividend_row.get('dividend_amount', 0)
                    weekly_data.loc[closest_date, 'allotment_ratio'] = dividend_row.get('allotment_ratio', 0)
                    weekly_data.loc[closest_date, 'allotment_price'] = dividend_row.get('allotment_price', 0)
                    weekly_data.loc[closest_date, 'bonus_ratio'] = dividend_row.get('bonus_ratio', 0)
                    weekly_data.loc[closest_date, 'transfer_ratio'] = dividend_row.get('transfer_ratio', 0)
                    
                    logger.debug(f"åˆ†çº¢é…è‚¡ä¿¡æ¯å·²å¯¹é½: {ex_date.date()} -> {closest_date.date()}")
            
            return weekly_data
            
        except Exception as e:
            logger.error(f"åˆ†çº¢é…è‚¡æ•°æ®å¯¹é½å¤±è´¥: {str(e)}")
            # è¿”å›åŸå§‹æ•°æ®ï¼Œæ·»åŠ ç©ºçš„åˆ†çº¢é…è‚¡åˆ—
            weekly_data['dividend_amount'] = 0.0
            weekly_data['allotment_ratio'] = 0.0
            weekly_data['allotment_price'] = 0.0
            weekly_data['bonus_ratio'] = 0.0
            weekly_data['transfer_ratio'] = 0.0
            return weekly_data
    
    def _process_dividend_data(self, raw_data: pd.DataFrame) -> pd.DataFrame:
        """
        å¤„ç†åŸå§‹åˆ†çº¢é…è‚¡æ•°æ®
        
        Args:
            raw_data: åŸå§‹åˆ†çº¢æ•°æ®
            
        Returns:
            pd.DataFrame: å¤„ç†åçš„åˆ†çº¢æ•°æ®ï¼Œä»¥é™¤æƒæ—¥ä¸ºç´¢å¼•
        """
        if raw_data is None or raw_data.empty:
            return pd.DataFrame()
        
        try:
            # åˆ›å»ºæ ‡å‡†åŒ–çš„åˆ†çº¢æ•°æ®ç»“æ„
            processed_data = pd.DataFrame()
            
            # æ ¹æ®å®é™…çš„åˆ—åè¿›è¡Œæ˜ å°„å’Œå¤„ç†
            if 'é™¤æƒé™¤æ¯æ—¥' in raw_data.columns:
                processed_data['ex_date'] = pd.to_datetime(raw_data['é™¤æƒé™¤æ¯æ—¥'])
            elif 'é™¤æƒæ—¥' in raw_data.columns:
                processed_data['ex_date'] = pd.to_datetime(raw_data['é™¤æƒæ—¥'])
            elif 'ex_date' in raw_data.columns:
                processed_data['ex_date'] = pd.to_datetime(raw_data['ex_date'])
            else:
                logger.warning("æœªæ‰¾åˆ°é™¤æƒæ—¥åˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºæ—¥æœŸ")
                processed_data['ex_date'] = pd.to_datetime(raw_data.iloc[:, 0])
            
            # åˆ†çº¢é‡‘é¢ (æ´¾æ¯) - æ³¨æ„ï¼šakshareè¿”å›çš„é€šå¸¸æ˜¯æ¯10è‚¡åˆ†çº¢é‡‘é¢ï¼Œéœ€è¦é™¤ä»¥10è½¬æ¢ä¸ºæ¯è‚¡é‡‘é¢
            if 'æ´¾æ¯' in raw_data.columns:
                processed_data['dividend_amount'] = pd.to_numeric(raw_data['æ´¾æ¯'], errors='coerce').fillna(0) / 10.0
            elif 'åˆ†çº¢é‡‘é¢' in raw_data.columns:
                processed_data['dividend_amount'] = pd.to_numeric(raw_data['åˆ†çº¢é‡‘é¢'], errors='coerce').fillna(0) / 10.0
            elif 'dividend' in raw_data.columns:
                processed_data['dividend_amount'] = pd.to_numeric(raw_data['dividend'], errors='coerce').fillna(0) / 10.0
            else:
                processed_data['dividend_amount'] = 0
            
            # é€è‚¡æ¯”ä¾‹ - æ³¨æ„ï¼šakshareè¿”å›çš„æ˜¯æ¯10è‚¡é€Xè‚¡ï¼Œéœ€è¦é™¤ä»¥10è½¬æ¢ä¸ºæ¯è‚¡é€è‚¡æ¯”ä¾‹
            if 'é€è‚¡' in raw_data.columns:
                processed_data['bonus_ratio'] = pd.to_numeric(raw_data['é€è‚¡'], errors='coerce').fillna(0) / 10.0
            elif 'é€è‚¡æ¯”ä¾‹' in raw_data.columns:
                processed_data['bonus_ratio'] = pd.to_numeric(raw_data['é€è‚¡æ¯”ä¾‹'], errors='coerce').fillna(0) / 10.0
            elif 'bonus' in raw_data.columns:
                processed_data['bonus_ratio'] = pd.to_numeric(raw_data['bonus'], errors='coerce').fillna(0) / 10.0
            else:
                processed_data['bonus_ratio'] = 0
            
            # è½¬å¢æ¯”ä¾‹ - æ³¨æ„ï¼šakshareè¿”å›çš„æ˜¯æ¯10è‚¡è½¬å¢Xè‚¡ï¼Œéœ€è¦é™¤ä»¥10è½¬æ¢ä¸ºæ¯è‚¡è½¬å¢æ¯”ä¾‹
            if 'è½¬å¢' in raw_data.columns:
                processed_data['transfer_ratio'] = pd.to_numeric(raw_data['è½¬å¢'], errors='coerce').fillna(0) / 10.0
            elif 'è½¬å¢æ¯”ä¾‹' in raw_data.columns:
                processed_data['transfer_ratio'] = pd.to_numeric(raw_data['è½¬å¢æ¯”ä¾‹'], errors='coerce').fillna(0) / 10.0
            elif 'transfer' in raw_data.columns:
                processed_data['transfer_ratio'] = pd.to_numeric(raw_data['transfer'], errors='coerce').fillna(0)
            else:
                processed_data['transfer_ratio'] = 0
            
            # é…è‚¡æ¯”ä¾‹å’Œä»·æ ¼ (æš‚æ—¶è®¾ä¸º0ï¼Œå› ä¸ºåŸå§‹æ•°æ®ä¸­æ²¡æœ‰è¿™äº›å­—æ®µ)
            processed_data['allotment_ratio'] = 0
            processed_data['allotment_price'] = 0
            
            # è®¾ç½®é™¤æƒæ—¥ä¸ºç´¢å¼•
            processed_data.set_index('ex_date', inplace=True)
            processed_data.sort_index(inplace=True)
            
            # è¿‡æ»¤æ‰æ‰€æœ‰å€¼éƒ½ä¸º0çš„è¡Œ
            mask = (processed_data['dividend_amount'] > 0) | \
                   (processed_data['bonus_ratio'] > 0) | \
                   (processed_data['transfer_ratio'] > 0) | \
                   (processed_data['allotment_ratio'] > 0)
            processed_data = processed_data[mask]
            
            logger.info(f"å¤„ç†åˆ†çº¢æ•°æ®å®Œæˆï¼Œæœ‰æ•ˆè®°å½•æ•°: {len(processed_data)}")
            return processed_data
            
        except Exception as e:
            logger.error(f"å¤„ç†åˆ†çº¢æ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()

# å·¥å‚å‡½æ•°
def create_data_fetcher(source: str = 'akshare') -> DataFetcher:
    """
    åˆ›å»ºæ•°æ®è·å–å™¨
    
    Args:
        source: æ•°æ®æºåç§°
        
    Returns:
        DataFetcher: æ•°æ®è·å–å™¨å®ä¾‹
        
    Raises:
        DataFetchError: ä¸æ”¯æŒçš„æ•°æ®æº
    """
    if source.lower() == 'akshare':
        return AkshareDataFetcher()
    else:
        raise DataFetchError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {source}")

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    fetcher = AkshareDataFetcher()
    
    # æµ‹è¯•è¿æ¥
    if fetcher.test_connection():
        print("âœ… Akshareè¿æ¥æ­£å¸¸")
    else:
        print("âŒ Akshareè¿æ¥å¤±è´¥")
    
    # æµ‹è¯•è·å–å•åªè‚¡ç¥¨æ•°æ®
    try:
        data = fetcher.get_stock_data('601088', '2023-01-01', '2023-12-31', 'weekly')
        print(f"âœ… æˆåŠŸè·å–ä¸­å›½ç¥åå‘¨çº¿æ•°æ®ï¼Œå…± {len(data)} æ¡è®°å½•")
        print(data.head())
    except Exception as e:
        print(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")