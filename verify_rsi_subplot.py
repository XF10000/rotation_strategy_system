"""
éªŒè¯RSIå­å›¾æ˜¯å¦æ­£ç¡®é›†æˆåˆ°HTMLæŠ¥å‘Šä¸­çš„è„šæœ¬
"""
import re
import json
import logging
from datetime import datetime
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def extract_js_config(html_content):
    """ä»HTMLä¸­æå–EChartsé…ç½®"""
    # æŸ¥æ‰¾optioné…ç½®
    option_match = re.search(r'const option\s*=\s*\{([^}]+)\};', html_content, re.DOTALL)
    if not option_match:
        logger.error("æœªæ‰¾åˆ°EChartsé…ç½®")
        return None
    
    return option_match.group(1)

def verify_rsi_data(html_content):
    """éªŒè¯RSIæ•°æ®æ˜¯å¦æ­£ç¡®æ³¨å…¥"""
    # æŸ¥æ‰¾RSIæ•°æ®æ³¨å…¥éƒ¨åˆ†
    rsi_data_match = re.search(r'// å‡†å¤‡RSIæ•°æ®[\s\S]*?const rsiPoints\s*=\s*stockData\.rsi\s*\|\|\s*\[\];', html_content)
    if rsi_data_match:
        logger.info("âœ… RSIæ•°æ®æ³¨å…¥ä»£ç å­˜åœ¨")
        return True
    else:
        logger.error("âŒ æœªæ‰¾åˆ°RSIæ•°æ®æ³¨å…¥ä»£ç ")
        return False

def verify_rsi_series(html_content):
    """éªŒè¯RSIç³»åˆ—é…ç½®æ˜¯å¦æ­£ç¡®"""
    # æŸ¥æ‰¾RSIç³»åˆ—é…ç½®
    rsi_series_match = re.search(r'//\s*RSIå­å›¾ç³»åˆ—[\s\S]*?name:\s*[\'\"]RSI[\'\"]', html_content)
    if rsi_series_match:
        logger.info("âœ… RSIç³»åˆ—é…ç½®å­˜åœ¨")
        
        # æ£€æŸ¥å¿…è¦çš„é…ç½®é¡¹
        series_config = rsi_series_match.group(0)
        checks = [
            ("xAxisIndex: 2", "xAxisIndexé…ç½®"),
            ("yAxisIndex: 2", "yAxisIndexé…ç½®"),
            ("gridIndex: 2", "gridIndexé…ç½®"),
            ("type: 'line'", "å›¾è¡¨ç±»å‹é…ç½®"),
            ("symbol: 'none'", "ç¬¦å·é…ç½®"),
            ("smooth: true", "å¹³æ»‘é…ç½®")
        ]
        
        for check, desc in checks:
            if check in series_config:
                logger.info(f"  âœ… {desc}æ­£ç¡®")
            else:
                logger.error(f"  âŒ {desc}ç¼ºå¤±")
                return False
        
        return True
    else:
        logger.error("âŒ æœªæ‰¾åˆ°RSIç³»åˆ—é…ç½®")
        return False

def verify_rsi_grid(html_content):
    """éªŒè¯RSIç½‘æ ¼é…ç½®æ˜¯å¦æ­£ç¡®"""
    # æŸ¥æ‰¾gridé…ç½®
    grid_match = re.search(r'grid:\s*\[[\s\S]*?\]', html_content)
    if grid_match:
        grid_config = grid_match.group(0)
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‰ä¸ªgridé…ç½®
        grid_configs = re.findall(r'\{[^}]*\}', grid_config)
        if len(grid_configs) >= 3:
            third_grid = grid_configs[2]
            if "top: '80%'" in third_grid and "height: '15%'" in third_grid:
                logger.info("âœ… RSIç½‘æ ¼é…ç½®æ­£ç¡®")
                return True
            else:
                logger.error("âŒ RSIç½‘æ ¼é…ç½®ä¸æ­£ç¡®")
                return False
        else:
            logger.error("âŒ ç½‘æ ¼é…ç½®æ•°é‡ä¸è¶³")
            return False
    else:
        logger.error("âŒ æœªæ‰¾åˆ°ç½‘æ ¼é…ç½®")
        return False

def verify_rsi_axes(html_content):
    """éªŒè¯RSIåæ ‡è½´é…ç½®æ˜¯å¦æ­£ç¡®"""
    # æŸ¥æ‰¾yAxisé…ç½®
    yaxis_match = re.search(r'yAxis:\s*\[[\s\S]*?\]', html_content)
    if yaxis_match:
        yaxis_config = yaxis_match.group(0)
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¬¬ä¸‰ä¸ªyAxisé…ç½®ï¼ˆRSIï¼‰
        yaxis_configs = re.findall(r'\{[^}]*\}', yaxis_config)
        if len(yaxis_configs) >= 3:
            third_yaxis = yaxis_configs[2]
            if "gridIndex: 2" in third_yaxis and "min: 0" in third_yaxis and "max: 100" in third_yaxis:
                logger.info("âœ… RSIåæ ‡è½´é…ç½®æ­£ç¡®")
                return True
            else:
                logger.error("âŒ RSIåæ ‡è½´é…ç½®ä¸æ­£ç¡®")
                return False
        else:
            logger.error("âŒ yAxisé…ç½®æ•°é‡ä¸è¶³")
            return False
    else:
        logger.error("âŒ æœªæ‰¾åˆ°yAxisé…ç½®")
        return False

def verify_legend(html_content):
    """éªŒè¯å›¾ä¾‹æ˜¯å¦åŒ…å«RSI"""
    legend_match = re.search(r'legend:\s*\{[^}]*data:\s*\[([^\]]+)\]', html_content)
    if legend_match:
        legend_data = legend_match.group(1)
        if "'RSI'" in legend_data or '"RSI"' in legend_data:
            logger.info("âœ… å›¾ä¾‹åŒ…å«RSI")
            return True
        else:
            logger.error("âŒ å›¾ä¾‹ä¸åŒ…å«RSI")
            return False
    else:
        logger.error("âŒ æœªæ‰¾åˆ°å›¾ä¾‹é…ç½®")
        return False

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    # æ£€æŸ¥æœ€æ–°çš„backtest_report.htmlæ–‡ä»¶
    reports_dir = Path("reports/enhanced_main")
    latest_report = reports_dir / "backtest_report.html"
    
    if not latest_report.exists():
        # å¦‚æœæœ€æ–°çš„æŠ¥å‘Šä¸å­˜åœ¨ï¼ŒæŸ¥æ‰¾å¸¦æ—¶é—´æˆ³çš„æŠ¥å‘Š
        html_files = list(reports_dir.glob("backtest_report_*.html"))
        if not html_files:
            logger.error("æœªæ‰¾åˆ°HTMLæŠ¥å‘Šæ–‡ä»¶")
            return False
        # é€‰æ‹©æœ€æ–°çš„æŠ¥å‘Š
        latest_report = max(html_files, key=lambda x: x.stat().st_mtime)
    
    logger.info(f"éªŒè¯æŠ¥å‘Š: {latest_report}")
    
    # è¯»å–HTMLå†…å®¹
    try:
        with open(latest_report, 'r', encoding='utf-8') as f:
            html_content = f.read()
    except Exception as e:
        logger.error(f"è¯»å–HTMLæ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # æ‰§è¡Œå„é¡¹éªŒè¯
    checks = [
        ("RSIæ•°æ®æ³¨å…¥", lambda: verify_rsi_data(html_content)),
        ("RSIç³»åˆ—é…ç½®", lambda: verify_rsi_series(html_content)),
        ("RSIç½‘æ ¼é…ç½®", lambda: verify_rsi_grid(html_content)),
        ("RSIåæ ‡è½´é…ç½®", lambda: verify_rsi_axes(html_content)),
        ("å›¾ä¾‹é…ç½®", lambda: verify_legend(html_content))
    ]
    
    results = []
    for check_name, check_func in checks:
        logger.info(f"\næ£€æŸ¥ {check_name}:")
        result = check_func()
        results.append(result)
    
    # è¾“å‡ºæ€»ç»“
    passed = sum(results)
    total = len(results)
    logger.info(f"\n\néªŒè¯ç»“æœ: {passed}/{total} é¡¹é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼ŒRSIå­å›¾å·²æ­£ç¡®é›†æˆï¼")
        return True
    else:
        logger.error("âŒ éƒ¨åˆ†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        return False

if __name__ == "__main__":
    main()
