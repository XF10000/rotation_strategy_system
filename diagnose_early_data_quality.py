#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†å²æ•°æ®è´¨é‡è¯Šæ–­è„šæœ¬
ç”¨äºåˆ†æ2015å¹´å¼€å§‹å›æµ‹æ—¶æŠ€æœ¯æŒ‡æ ‡å¼‚å¸¸çš„æ ¹æœ¬åŸå› 

é—®é¢˜èƒŒæ™¯ï¼š
- å›æµ‹èµ·å§‹æ—¶é—´æå‰åˆ°2015å¹´1æœˆ8æ—¥æ—¶ï¼Œ2019å¹´ä»¥å‰çš„æŠ€æœ¯æŒ‡æ ‡å˜æˆç›´çº¿
- ä¸­å›½ç¥åç­‰å¤§å‹è‚¡ç¥¨ä¹Ÿå‡ºç°æ­¤é—®é¢˜ï¼Œæ’é™¤æ•°æ®ä¸è¶³çš„å¯èƒ½
- éœ€è¦å®šä½æ˜¯æ•°æ®è´¨é‡é—®é¢˜è¿˜æ˜¯ä»£ç é€»è¾‘é—®é¢˜
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data.data_fetcher import AkshareDataFetcher
from data.data_processor import DataProcessor
from strategy.signal_generator import SignalGenerator
from config.csv_config_loader import load_backtest_settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_quality_diagnosis.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class EarlyDataQualityDiagnoser:
    """æ—©æœŸæ•°æ®è´¨é‡è¯Šæ–­å™¨"""
    
    def __init__(self):
        self.data_fetcher = AkshareDataFetcher()
        self.data_processor = DataProcessor()
        
    def diagnose_stock_data_quality(self, stock_code: str, start_date: str = "2015-01-08"):
        """
        è¯Šæ–­å•åªè‚¡ç¥¨çš„æ•°æ®è´¨é‡
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ” å¼€å§‹è¯Šæ–­è‚¡ç¥¨ {stock_code} çš„æ•°æ®è´¨é‡")
        logger.info(f"ğŸ• å›æµ‹å¼€å§‹æ—¥æœŸ: {start_date}")
        logger.info(f"{'='*60}")
        
        try:
            # 1. è·å–åŸå§‹æ•°æ®
            logger.info("ğŸ“Š æ­¥éª¤1: è·å–åŸå§‹è‚¡ç¥¨æ•°æ®...")
            
            # è®¡ç®—éœ€è¦çš„å†å²æ•°æ®èµ·å§‹æ—¥æœŸï¼ˆ125å‘¨å†å²æ•°æ®ï¼‰
            start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            history_start = start_dt - timedelta(weeks=125)
            history_start_str = history_start.strftime("%Y-%m-%d")
            
            logger.info(f"   - å†å²æ•°æ®èµ·å§‹æ—¥æœŸ: {history_start_str}")
            logger.info(f"   - å›æµ‹å¼€å§‹æ—¥æœŸ: {start_date}")
            
            # è·å–è‚¡ç¥¨æ•°æ®
            stock_data = self.data_fetcher.get_stock_data(
                stock_code, 
                start_date=history_start_str,
                end_date="2025-01-01"  # è·å–åˆ°å½“å‰
            )
            
            if stock_data is None or stock_data.empty:
                logger.error(f"âŒ æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„æ•°æ®")
                return None
                
            logger.info(f"   - åŸå§‹æ•°æ®è¡Œæ•°: {len(stock_data)}")
            logger.info(f"   - æ•°æ®æ—¶é—´èŒƒå›´: {stock_data.index.min()} åˆ° {stock_data.index.max()}")
            
            # 2. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
            logger.info("\nğŸ“‹ æ­¥éª¤2: æ•°æ®å®Œæ•´æ€§æ£€æŸ¥...")
            self._check_data_completeness(stock_data, history_start_str, start_date)
            
            # 3. æ•°æ®è´¨é‡æ£€æŸ¥
            logger.info("\nğŸ”¬ æ­¥éª¤3: æ•°æ®è´¨é‡æ£€æŸ¥...")
            self._check_data_quality(stock_data)
            
            # 4. é‡é‡‡æ ·ä¸ºå‘¨çº¿æ•°æ®
            logger.info("\nğŸ“ˆ æ­¥éª¤4: é‡é‡‡æ ·ä¸ºå‘¨çº¿æ•°æ®...")
            weekly_data = self.data_processor.resample_to_weekly(stock_data)
            logger.info(f"   - å‘¨çº¿æ•°æ®è¡Œæ•°: {len(weekly_data)}")
            logger.info(f"   - å‘¨çº¿æ—¶é—´èŒƒå›´: {weekly_data.index.min()} åˆ° {weekly_data.index.max()}")
            
            # 5. æŠ€æœ¯æŒ‡æ ‡è®¡ç®—è¯Šæ–­
            logger.info("\nğŸ”§ æ­¥éª¤5: æŠ€æœ¯æŒ‡æ ‡è®¡ç®—è¯Šæ–­...")
            self._diagnose_technical_indicators(weekly_data, start_date)
            
            # 6. ä¿¡å·ç”Ÿæˆå™¨è¯Šæ–­
            logger.info("\nğŸ¯ æ­¥éª¤6: ä¿¡å·ç”Ÿæˆå™¨è¯Šæ–­...")
            self._diagnose_signal_generator(stock_code, weekly_data, start_date)
            
            return weekly_data
            
        except Exception as e:
            logger.error(f"âŒ è¯Šæ–­è‚¡ç¥¨ {stock_code} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def _check_data_completeness(self, data: pd.DataFrame, history_start: str, backtest_start: str):
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_data = data.isnull().sum()
        logger.info(f"   - ç¼ºå¤±å€¼ç»Ÿè®¡:")
        for col, missing_count in missing_data.items():
            if missing_count > 0:
                logger.warning(f"     {col}: {missing_count} ä¸ªç¼ºå¤±å€¼")
            else:
                logger.info(f"     {col}: æ— ç¼ºå¤±å€¼")
        
        # æ£€æŸ¥æ—¶é—´è¿ç»­æ€§
        date_range = pd.date_range(start=history_start, end=data.index.max(), freq='D')
        trading_days = len([d for d in date_range if d.weekday() < 5])  # å·¥ä½œæ—¥
        actual_days = len(data)
        
        logger.info(f"   - æ—¶é—´è¿ç»­æ€§æ£€æŸ¥:")
        logger.info(f"     æœŸé—´æ€»å·¥ä½œæ—¥: {trading_days}")
        logger.info(f"     å®é™…æ•°æ®å¤©æ•°: {actual_days}")
        logger.info(f"     æ•°æ®å®Œæ•´ç‡: {actual_days/trading_days*100:.1f}%")
        
        # æ£€æŸ¥å…³é”®æ—¶é—´ç‚¹çš„æ•°æ®
        backtest_start_dt = datetime.strptime(backtest_start, "%Y-%m-%d")
        key_dates = [
            backtest_start_dt - timedelta(days=365*2),  # å›æµ‹å‰2å¹´
            backtest_start_dt - timedelta(days=365),    # å›æµ‹å‰1å¹´
            backtest_start_dt,                          # å›æµ‹å¼€å§‹
            backtest_start_dt + timedelta(days=365*2),  # å›æµ‹å2å¹´
            backtest_start_dt + timedelta(days=365*4)   # å›æµ‹å4å¹´
        ]
        
        logger.info(f"   - å…³é”®æ—¶é—´ç‚¹æ•°æ®æ£€æŸ¥:")
        for date in key_dates:
            closest_data = data[data.index <= date]
            if not closest_data.empty:
                closest_date = closest_data.index.max()
                days_diff = (date - closest_date).days
                logger.info(f"     {date.strftime('%Y-%m-%d')}: æœ€è¿‘æ•°æ® {closest_date.strftime('%Y-%m-%d')} (ç›¸å·®{days_diff}å¤©)")
            else:
                logger.warning(f"     {date.strftime('%Y-%m-%d')}: âŒ æ— æ•°æ®")
    
    def _check_data_quality(self, data: pd.DataFrame):
        """æ£€æŸ¥æ•°æ®è´¨é‡"""
        
        # æ£€æŸ¥ä»·æ ¼åˆç†æ€§
        logger.info(f"   - ä»·æ ¼åˆç†æ€§æ£€æŸ¥:")
        
        for col in ['open', 'high', 'low', 'close']:
            if col in data.columns:
                prices = data[col]
                logger.info(f"     {col}: èŒƒå›´ {prices.min():.2f} - {prices.max():.2f}")
                
                # æ£€æŸ¥é›¶å€¼æˆ–è´Ÿå€¼
                zero_or_negative = (prices <= 0).sum()
                if zero_or_negative > 0:
                    logger.warning(f"     {col}: âŒ å‘ç° {zero_or_negative} ä¸ªé›¶å€¼æˆ–è´Ÿå€¼")
                
                # æ£€æŸ¥æç«¯å˜åŒ–
                pct_change = prices.pct_change().abs()
                extreme_changes = (pct_change > 0.5).sum()
                if extreme_changes > 0:
                    logger.warning(f"     {col}: âš ï¸ å‘ç° {extreme_changes} ä¸ªæç«¯å˜åŒ–(>50%)")
                    # æ˜¾ç¤ºæç«¯å˜åŒ–çš„æ—¥æœŸ
                    extreme_dates = data[pct_change > 0.5].index
                    for date in extreme_dates[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                        logger.warning(f"       æç«¯å˜åŒ–: {date.strftime('%Y-%m-%d')}")
        
        # æ£€æŸ¥OHLCé€»è¾‘
        if all(col in data.columns for col in ['open', 'high', 'low', 'close']):
            invalid_high = data['high'] < data[['open', 'close']].max(axis=1)
            invalid_low = data['low'] > data[['open', 'close']].min(axis=1)
            
            invalid_ohlc = (invalid_high | invalid_low).sum()
            if invalid_ohlc > 0:
                logger.warning(f"   - OHLCé€»è¾‘: âŒ å‘ç° {invalid_ohlc} æ¡é€»è¾‘é”™è¯¯")
            else:
                logger.info(f"   - OHLCé€»è¾‘: âœ… æ­£å¸¸")
        
        # æ£€æŸ¥æˆäº¤é‡
        if 'volume' in data.columns:
            volume = data['volume']
            zero_volume = (volume == 0).sum()
            negative_volume = (volume < 0).sum()
            
            logger.info(f"   - æˆäº¤é‡æ£€æŸ¥:")
            logger.info(f"     èŒƒå›´: {volume.min()} - {volume.max()}")
            if zero_volume > 0:
                logger.warning(f"     âš ï¸ é›¶æˆäº¤é‡: {zero_volume} ä¸ª")
            if negative_volume > 0:
                logger.warning(f"     âŒ è´Ÿæˆäº¤é‡: {negative_volume} ä¸ª")
    
    def _diagnose_technical_indicators(self, weekly_data: pd.DataFrame, backtest_start: str):
        """è¯Šæ–­æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
        
        try:
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            logger.info(f"   - è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
            indicators_data = self.data_processor.calculate_technical_indicators(weekly_data)
            
            # åˆ†æå„ä¸ªæ—¶é—´æ®µçš„æŠ€æœ¯æŒ‡æ ‡
            backtest_start_dt = datetime.strptime(backtest_start, "%Y-%m-%d")
            
            time_periods = [
                ("å†å²æ•°æ®æœŸ", indicators_data.index.min(), backtest_start_dt),
                ("å›æµ‹åˆæœŸ(2015-2017)", backtest_start_dt, backtest_start_dt + timedelta(days=365*2)),
                ("å›æµ‹ä¸­æœŸ(2017-2019)", backtest_start_dt + timedelta(days=365*2), backtest_start_dt + timedelta(days=365*4)),
                ("å›æµ‹åæœŸ(2019-2021)", backtest_start_dt + timedelta(days=365*4), backtest_start_dt + timedelta(days=365*6)),
                ("è¿‘æœŸ(2021è‡³ä»Š)", backtest_start_dt + timedelta(days=365*6), indicators_data.index.max())
            ]
            
            for period_name, start_date, end_date in time_periods:
                logger.info(f"\n   ğŸ“Š {period_name} ({start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}):")
                
                period_data = indicators_data[(indicators_data.index >= start_date) & (indicators_data.index <= end_date)]
                
                if period_data.empty:
                    logger.warning(f"     âŒ è¯¥æ—¶æœŸæ— æ•°æ®")
                    continue
                
                # æ£€æŸ¥RSI
                if 'rsi' in period_data.columns:
                    rsi = period_data['rsi'].dropna()
                    if len(rsi) > 0:
                        logger.info(f"     RSI: å‡å€¼={rsi.mean():.2f}, æ ‡å‡†å·®={rsi.std():.2f}, èŒƒå›´={rsi.min():.2f}-{rsi.max():.2f}")
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›´çº¿
                        if rsi.std() < 0.1:
                            logger.warning(f"     âš ï¸ RSIç–‘ä¼¼ç›´çº¿ (æ ‡å‡†å·®={rsi.std():.4f})")
                            logger.warning(f"     RSIå‰5ä¸ªå€¼: {rsi.head().values}")
                            logger.warning(f"     RSIå5ä¸ªå€¼: {rsi.tail().values}")
                    else:
                        logger.warning(f"     âŒ RSIå…¨ä¸ºNaN")
                
                # æ£€æŸ¥EMA
                for ema_col in ['ema_20', 'ema_50', 'ema_60']:
                    if ema_col in period_data.columns:
                        ema = period_data[ema_col].dropna()
                        if len(ema) > 0:
                            logger.info(f"     {ema_col.upper()}: æœ‰æ•ˆå€¼={len(ema)}, èŒƒå›´={ema.min():.2f}-{ema.max():.2f}")
                        else:
                            logger.warning(f"     âŒ {ema_col.upper()}å…¨ä¸ºNaN")
                
                # æ£€æŸ¥MACD
                if 'macd' in period_data.columns:
                    macd = period_data['macd'].dropna()
                    if len(macd) > 0:
                        logger.info(f"     MACD: æœ‰æ•ˆå€¼={len(macd)}, èŒƒå›´={macd.min():.4f}-{macd.max():.4f}")
                    else:
                        logger.warning(f"     âŒ MACDå…¨ä¸ºNaN")
                        
        except Exception as e:
            logger.error(f"   âŒ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
    
    def _diagnose_signal_generator(self, stock_code: str, weekly_data: pd.DataFrame, backtest_start: str):
        """è¯Šæ–­ä¿¡å·ç”Ÿæˆå™¨"""
        
        try:
            # åŠ è½½é…ç½®
            backtest_settings = load_backtest_settings()
            
            logger.info(f"   - æ‰¾åˆ°é…ç½®: å›æµ‹è®¾ç½®")
            
            # åˆ›å»ºä¿¡å·ç”Ÿæˆå™¨
            signal_generator = SignalGenerator(backtest_settings)
            
            # åˆ†æä¸åŒæ—¶æœŸçš„ä¿¡å·ç”Ÿæˆ
            backtest_start_dt = datetime.strptime(backtest_start, "%Y-%m-%d")
            
            # æ£€æŸ¥2015-2019å¹´æœŸé—´çš„ä¿¡å·
            early_period = weekly_data[
                (weekly_data.index >= backtest_start_dt) & 
                (weekly_data.index <= backtest_start_dt + timedelta(days=365*4))
            ].copy()
            
            if not early_period.empty:
                logger.info(f"   - åˆ†æ2015-2019å¹´æœŸé—´ä¿¡å·ç”Ÿæˆ...")
                
                # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
                early_with_indicators = self.data_processor.calculate_technical_indicators(early_period)
                
                # ç”Ÿæˆä¿¡å·
                for i, (date, row) in enumerate(early_with_indicators.iterrows()):
                    if i >= 10:  # åªæ£€æŸ¥å‰10ä¸ªä¿¡å·
                        break
                        
                    try:
                        signals = signal_generator.generate_signal(stock_code, early_with_indicators)
                        # ä»ä¿¡å·ç»“æœä¸­è·å–RSIå€¼
                        current_rsi = signals.get('technical_indicators', {}).get('rsi_14w', row.get('rsi', 'NaN'))
                        logger.info(f"     {date.strftime('%Y-%m-%d')}: RSI={current_rsi:.2f}, ä¿¡å·={signals.get('signal', 'UNKNOWN')}")
                        
                        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†é»˜è®¤å€¼
                        if abs(current_rsi - 70.0) < 0.01:
                            logger.warning(f"     âš ï¸ RSIç–‘ä¼¼ä½¿ç”¨é»˜è®¤å€¼70")
                        
                    except Exception as e:
                        logger.error(f"     âŒ ä¿¡å·ç”Ÿæˆå¤±è´¥ {date.strftime('%Y-%m-%d')}: {str(e)}")
                        
        except Exception as e:
            logger.error(f"   âŒ ä¿¡å·ç”Ÿæˆå™¨è¯Šæ–­å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

def compare_backtest_start_dates():
    """å¯¹æ¯”ä¸åŒå›æµ‹èµ·å§‹æ—¥æœŸçš„å·®å¼‚"""
    logger.info("ğŸ” å¯¹æ¯”ä¸åŒå›æµ‹èµ·å§‹æ—¥æœŸçš„å·®å¼‚")
    logger.info("=" * 80)
    
    diagnoser = EarlyDataQualityDiagnoser()
    
    # å¯¹æ¯”ä¸‰ä¸ªä¸åŒçš„èµ·å§‹æ—¥æœŸ
    start_dates = [
        "2015-01-08",  # ç”¨æˆ·å‘ç°é—®é¢˜çš„æ—¥æœŸ
        "2018-01-01",  # ä¸­é—´æ—¥æœŸ
        "2021-01-01"   # ç”¨æˆ·è¯´æ²¡é—®é¢˜çš„æ—¥æœŸ
    ]
    
    test_stock = "601088"  # ä¸­å›½ç¥å
    
    for start_date in start_dates:
        logger.info(f"\nğŸ—“ï¸ æµ‹è¯•å›æµ‹èµ·å§‹æ—¥æœŸ: {start_date}")
        logger.info("=" * 60)
        
        try:
            # è®¡ç®—å†å²æ•°æ®èµ·å§‹æ—¥æœŸ
            start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            history_start = start_dt - timedelta(weeks=125)
            history_start_str = history_start.strftime("%Y-%m-%d")
            
            logger.info(f"ğŸ“… å†å²æ•°æ®èµ·å§‹: {history_start_str}")
            logger.info(f"ğŸ“… å›æµ‹å¼€å§‹: {start_date}")
            logger.info(f"ğŸ“Š å†å²æ•°æ®ç¼“å†²æœŸ: {(start_dt - history_start).days / 365.25:.1f} å¹´")
            
            # è·å–æ•°æ®
            stock_data = diagnoser.data_fetcher.get_stock_data(
                test_stock, 
                start_date=history_start_str,
                end_date="2023-01-01"
            )
            
            if stock_data is None or stock_data.empty:
                logger.error(f"âŒ æ— æ³•è·å– {start_date} çš„æ•°æ®")
                continue
            
            # é‡é‡‡æ ·ä¸ºå‘¨çº¿
            weekly_data = diagnoser.data_processor.resample_to_weekly(stock_data)
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            indicators_data = diagnoser.data_processor.calculate_technical_indicators(weekly_data)
            
            # åˆ†æå›æµ‹æœŸé—´çš„RSI
            backtest_data = indicators_data[indicators_data.index >= start_dt]
            
            if not backtest_data.empty and 'rsi' in backtest_data.columns:
                rsi_data = backtest_data['rsi'].dropna()
                
                if len(rsi_data) > 0:
                    logger.info(f"ğŸ“ˆ å›æµ‹æœŸé—´RSIåˆ†æ:")
                    logger.info(f"   - æ•°æ®ç‚¹æ•°: {len(rsi_data)}")
                    logger.info(f"   - å‡å€¼: {rsi_data.mean():.2f}")
                    logger.info(f"   - æ ‡å‡†å·®: {rsi_data.std():.4f}")
                    logger.info(f"   - èŒƒå›´: {rsi_data.min():.2f} - {rsi_data.max():.2f}")
                    
                    # æ£€æŸ¥å‰10ä¸ªRSIå€¼
                    logger.info(f"   - å‰10ä¸ªRSIå€¼: {rsi_data.head(10).round(2).tolist()}")
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºç›´çº¿
                    if rsi_data.std() < 0.1:
                        logger.warning(f"   âš ï¸ RSIç–‘ä¼¼ç›´çº¿ (æ ‡å‡†å·®={rsi_data.std():.4f})")
                        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å€¼éƒ½ç›¸åŒ
                        unique_values = rsi_data.nunique()
                        logger.warning(f"   âš ï¸ RSIå”¯ä¸€å€¼æ•°é‡: {unique_values}")
                        if unique_values == 1:
                            logger.error(f"   âŒ æ‰€æœ‰RSIå€¼å®Œå…¨ç›¸åŒ: {rsi_data.iloc[0]:.2f}")
                    else:
                        logger.info(f"   âœ… RSIæ­£å¸¸æ³¢åŠ¨")
                
                else:
                    logger.error(f"   âŒ å›æµ‹æœŸé—´RSIå…¨ä¸ºNaN")
            else:
                logger.error(f"   âŒ æ— å›æµ‹æ•°æ®æˆ–RSIåˆ—")
                
            # æµ‹è¯•ä¿¡å·ç”Ÿæˆå™¨
            logger.info(f"\nğŸ¯ æµ‹è¯•ä¿¡å·ç”Ÿæˆå™¨:")
            try:
                backtest_settings = load_backtest_settings()
                signal_generator = SignalGenerator(backtest_settings)
                
                # æµ‹è¯•å‰5ä¸ªå›æµ‹æ—¥æœŸçš„ä¿¡å·ç”Ÿæˆ
                test_dates = backtest_data.head(5)
                for i, (date, row) in enumerate(test_dates.iterrows()):
                    try:
                        # è·å–åˆ°å½“å‰æ—¥æœŸä¸ºæ­¢çš„æ‰€æœ‰å†å²æ•°æ®
                        historical_data = weekly_data[weekly_data.index <= date]
                        
                        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®ï¼ˆè‡³å°‘60ä¸ªæ•°æ®ç‚¹ï¼‰
                        if len(historical_data) < 60:
                            logger.warning(f"   {date.strftime('%Y-%m-%d')}: å†å²æ•°æ®ä¸è¶³({len(historical_data)}ä¸ªç‚¹)ï¼Œè·³è¿‡")
                            continue
                        
                        # è°ƒç”¨ä¿¡å·ç”Ÿæˆå™¨
                        signals = signal_generator.generate_signal(test_stock, historical_data)
                        current_rsi = signals.get('technical_indicators', {}).get('rsi_14w', 'NaN')
                        signal_type = signals.get('signal', 'UNKNOWN')
                        
                        logger.info(f"   {date.strftime('%Y-%m-%d')}: RSI={current_rsi:.2f}, ä¿¡å·={signal_type}")
                        
                        # å¯¹æ¯”æ•°æ®å¤„ç†å™¨è®¡ç®—çš„RSI
                        data_rsi = historical_data['rsi'].iloc[-1] if 'rsi' in historical_data.columns else 'NaN'
                        if isinstance(data_rsi, (int, float)) and isinstance(current_rsi, (int, float)):
                            rsi_diff = abs(current_rsi - data_rsi)
                            if rsi_diff > 0.01:
                                logger.warning(f"   âš ï¸ RSIå·®å¼‚: ä¿¡å·ç”Ÿæˆå™¨={current_rsi:.2f}, æ•°æ®å¤„ç†å™¨={data_rsi:.2f}, å·®å¼‚={rsi_diff:.4f}")
                            else:
                                logger.info(f"   âœ… RSIä¸€è‡´: {current_rsi:.2f}")
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å›ºå®šå€¼
                        if isinstance(current_rsi, (int, float)):
                            if abs(current_rsi - 41.15) < 0.01 or abs(current_rsi - 50.0) < 0.01:  # å¸¸è§çš„å›ºå®šå€¼
                                logger.warning(f"   âš ï¸ å‘ç°ç–‘ä¼¼å›ºå®šRSIå€¼: {current_rsi}")
                            
                    except Exception as e:
                        logger.error(f"   âŒ ä¿¡å·ç”Ÿæˆå¤±è´¥ {date.strftime('%Y-%m-%d')}: {str(e)}")
                        import traceback
                        logger.error(traceback.format_exc())
                        
            except Exception as e:
                logger.error(f"   âŒ ä¿¡å·ç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {str(e)}")
                
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯• {start_date} å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
    
    # æ€»ç»“åˆ†æ
    logger.info(f"\nğŸ“‹ å¯¹æ¯”åˆ†ææ€»ç»“:")
    logger.info("=" * 80)
    logger.info("ğŸ” è¯·æ£€æŸ¥ä¸Šè¿°æ—¥å¿—ï¼Œå¯¹æ¯”ä¸åŒèµ·å§‹æ—¥æœŸçš„å·®å¼‚:")
    logger.info("   1. å†å²æ•°æ®ç¼“å†²æœŸé•¿åº¦çš„å½±å“")
    logger.info("   2. RSIè®¡ç®—ç»“æœçš„å·®å¼‚")
    logger.info("   3. ä¿¡å·ç”Ÿæˆå™¨è¡Œä¸ºçš„å·®å¼‚")
    logger.info("   4. æ•°æ®è¾¹ç•Œæ•ˆåº”çš„å½±å“")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å›æµ‹èµ·å§‹æ—¥æœŸå¯¹æ¯”åˆ†æ")
    logger.info("=" * 80)
    
    # æ‰§è¡Œå¯¹æ¯”åˆ†æ
    compare_backtest_start_dates()
    
    logger.info("\nğŸ“ è¯¦ç»†åˆ†ææ—¥å¿—å·²ä¿å­˜åˆ°: data_quality_diagnosis.log")
    logger.info("ğŸ¯ å¯¹æ¯”åˆ†æå®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸åŒèµ·å§‹æ—¥æœŸçš„å·®å¼‚")

if __name__ == "__main__":
    main()