#!/usr/bin/env python3
"""
æ•°æ®ç¼“å­˜é—®é¢˜ä¿®å¤å·¥å…· - æ·±åº¦ä¿®å¤ç‰ˆæœ¬
è§£å†³2024å¹´8æœˆå‰æŠ€æœ¯æŒ‡æ ‡ç¼ºå¤±å’Œåˆ—åä¸åŒ¹é…é—®é¢˜

æ³¨æ„ï¼šä»V2.0å¼€å§‹ï¼Œmain.pyå·²é›†æˆè‡ªåŠ¨ç¼“å­˜éªŒè¯å’Œä¿®å¤åŠŸèƒ½ã€‚
æœ¬å·¥å…·ä»…ç”¨äºå¤„ç†è‡ªåŠ¨ä¿®å¤æ— æ³•è§£å†³çš„å¤æ‚é—®é¢˜ã€‚
æ­£å¸¸æƒ…å†µä¸‹ï¼Œæ‚¨ä¸éœ€è¦æ‰‹åŠ¨è¿è¡Œæ­¤å·¥å…·ã€‚
"""

import pandas as pd
import numpy as np
import os
import json
import logging
from datetime import datetime
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def fix_cache_issues():
    """ä¿®å¤ç¼“å­˜æ•°æ®é—®é¢˜"""
    
    logger.info("ğŸš€ å¼€å§‹ä¿®å¤æ•°æ®ç¼“å­˜é—®é¢˜...")
    
    # 1. æ¸…ç†æ‰€æœ‰è‚¡ç¥¨æ•°æ®ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°è®¡ç®—
    cache_dir = Path('data_cache')
    stock_data_dir = cache_dir / 'stock_data'
    
    if stock_data_dir.exists():
        logger.info("ğŸ—‘ï¸ æ¸…ç†ç°æœ‰è‚¡ç¥¨æ•°æ®ç¼“å­˜...")
        
        # æ¸…ç†æ—¥çº¿å’Œå‘¨çº¿ç¼“å­˜
        for period in ['daily', 'weekly']:
            period_dir = stock_data_dir / period
            if period_dir.exists():
                # åˆ é™¤æ‰€æœ‰CSVå’ŒJSONæ–‡ä»¶
                csv_files = list(period_dir.glob('*.csv'))
                json_files = list(period_dir.glob('*.json'))
                
                for file in csv_files + json_files:
                    file.unlink()
                    
                logger.info(f"   æ¸…ç† {period} ç›®å½•: {len(csv_files)} CSV + {len(json_files)} JSON")
    
    # 2. æ¸…ç†æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜
    indicators_dir = cache_dir / 'indicators'
    if indicators_dir.exists():
        indicator_files = list(indicators_dir.glob('*.csv'))
        for file in indicator_files:
            file.unlink()
        logger.info(f"ğŸ—‘ï¸ æ¸…ç†æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜: {len(indicator_files)} ä¸ªæ–‡ä»¶")
    
    # 3. æ¸…ç†ä¿¡å·ç¼“å­˜
    signals_dir = cache_dir / 'signals'
    if signals_dir.exists():
        import shutil
        shutil.rmtree(signals_dir)
        signals_dir.mkdir(exist_ok=True)
        logger.info("ğŸ—‘ï¸ æ¸…ç†ä¿¡å·ç¼“å­˜ç›®å½•")
    
    logger.info("âœ… ç¼“å­˜æ¸…ç†å®Œæˆï¼Œç³»ç»Ÿå°†é‡æ–°è·å–å’Œè®¡ç®—æ‰€æœ‰æ•°æ®")
    
    # 4. éªŒè¯è¡Œä¸šæ˜ å°„æ–‡ä»¶
    industry_map_file = cache_dir / 'stock_to_industry_map.json'
    if industry_map_file.exists():
        try:
            with open(industry_map_file, 'r', encoding='utf-8') as f:
                map_data = json.load(f)
            
            mapping = map_data.get('mapping', {})
            logger.info(f"âœ… è¡Œä¸šæ˜ å°„æ–‡ä»¶æ­£å¸¸: {len(mapping)} åªè‚¡ç¥¨")
            
            # æ£€æŸ¥å…³é”®è‚¡ç¥¨
            test_stocks = ['600985', '601225', '601088']
            for stock in test_stocks:
                if stock in mapping:
                    industry_info = mapping[stock]
                    logger.info(f"   {stock}: {industry_info.get('industry_name', 'æœªçŸ¥')}")
                else:
                    logger.warning(f"   {stock}: æ˜ å°„ç¼ºå¤±")
                    
        except Exception as e:
            logger.error(f"âŒ è¡Œä¸šæ˜ å°„æ–‡ä»¶æœ‰é—®é¢˜: {e}")
            return False
    else:
        logger.error("âŒ è¡Œä¸šæ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ")
        return False
    
    return True

def validate_technical_indicators():
    """éªŒè¯æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æ˜¯å¦æ­£ç¡®"""
    
    logger.info("ğŸ” éªŒè¯æŠ€æœ¯æŒ‡æ ‡è®¡ç®—...")
    
    # å¯¼å…¥å¿…è¦çš„æ¨¡å—
    import sys
    sys.path.append('.')
    
    from indicators.trend import calculate_ema
    from indicators.momentum import calculate_rsi, calculate_macd
    from indicators.volatility import calculate_bollinger_bands
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dates = pd.date_range('2020-01-01', '2025-08-01', freq='W')
    np.random.seed(42)  # å›ºå®šéšæœºç§å­
    
    test_data = pd.DataFrame({
        'close': 10 + np.cumsum(np.random.randn(len(dates)) * 0.1),
        'high': 0,
        'low': 0,
        'volume': np.random.randint(100000, 1000000, len(dates))
    }, index=dates)
    
    # è°ƒæ•´highå’Œlow
    test_data['high'] = test_data['close'] * (1 + np.random.uniform(0, 0.05, len(dates)))
    test_data['low'] = test_data['close'] * (1 - np.random.uniform(0, 0.05, len(dates)))
    
    logger.info(f"ğŸ“Š æµ‹è¯•æ•°æ®: {len(test_data)} æ¡è®°å½•")
    
    try:
        # æµ‹è¯•å„é¡¹æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
        logger.info("   æµ‹è¯•EMAè®¡ç®—...")
        ema_20 = calculate_ema(test_data['close'], 20)
        logger.info(f"   EMA20: {len(ema_20.dropna())} ä¸ªæœ‰æ•ˆå€¼")
        
        logger.info("   æµ‹è¯•RSIè®¡ç®—...")
        rsi_14 = calculate_rsi(test_data['close'], 14)
        logger.info(f"   RSI14: {len(rsi_14.dropna())} ä¸ªæœ‰æ•ˆå€¼")
        
        logger.info("   æµ‹è¯•MACDè®¡ç®—...")
        macd_result = calculate_macd(test_data['close'])
        logger.info(f"   MACD: DIF={len(macd_result['dif'].dropna())} ä¸ªæœ‰æ•ˆå€¼")
        
        logger.info("   æµ‹è¯•å¸ƒæ—å¸¦è®¡ç®—...")
        bb_result = calculate_bollinger_bands(test_data['close'], 20, 2)
        logger.info(f"   å¸ƒæ—å¸¦: {len(bb_result['upper'].dropna())} ä¸ªæœ‰æ•ˆå€¼")
        
        logger.info("âœ… æŠ€æœ¯æŒ‡æ ‡è®¡ç®—éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ”§ æ•°æ®ç¼“å­˜é—®é¢˜ä¿®å¤å·¥å…·")
    logger.info("=" * 60)
    
    # 1. ä¿®å¤ç¼“å­˜é—®é¢˜
    if not fix_cache_issues():
        logger.error("âŒ ç¼“å­˜ä¿®å¤å¤±è´¥")
        return 1
    
    # 2. éªŒè¯æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
    if not validate_technical_indicators():
        logger.error("âŒ æŠ€æœ¯æŒ‡æ ‡éªŒè¯å¤±è´¥")
        return 1
    
    logger.info("=" * 60)
    logger.info("âœ… ä¿®å¤å®Œæˆï¼å»ºè®®æ­¥éª¤ï¼š")
    logger.info("1. è¿è¡Œ python3 main.py é‡æ–°è¿›è¡Œå›æµ‹")
    logger.info("2. æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡æ˜¯å¦æ­£ç¡®è®¡ç®—")
    logger.info("3. éªŒè¯äº¤æ˜“ä¿¡å·æ˜¯å¦æ­£å¸¸ç”Ÿæˆ")
    logger.info("=" * 60)
    
    return 0

if __name__ == "__main__":
    exit(main())
